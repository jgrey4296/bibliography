@techreport{CBCL-115,
 author       = {Niyogi, Partha and Berwick, Robert},
 title        = {The Logical Problem of Language Change},
 year         = {1995},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper considers the problem of language change. Linguists must explain not only how languages are learned but also how and why they have evolved along certain trajectories and not others. While the language learning problem has focused on the behavior of individuals and how they acquire a particular grammar from a class of grammars $cal G$, here we consider a population of such learners and investigate the emergent, global population characteristics of linguistic communities over several generations. We argue that language change follows logically from specific assumptions about grammatical theories and learning paradigms. In particular, we are able to transform parameterized theories and memoryless acquisition algorithms into grammatical dynamical systems, whose evolution depicts a population's evolving linguistic composition. We investigate the linguistic and computational consequences of this model, showing that the formalization allows one to ask questions about diachronic that one otherwise could not ask, such as the effect of varying initial conditions on the resulting diachronic trajectories. From a more programmatic perspective, we give an example of how the dynamical system model for language change can serve as a way to distinguish among alternative grammatical theories, introducing a formal diachronic adequacy criterion for linguistic theories.},
 month        = {dec~6},
 number       = {CBCL-115},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1516.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1516.pdf},
}

@techreport{CBCL-116,
 author       = {Sung, Kah Kay and Niyogi, Partha},
 title        = {A Formulation for Active Learning with Applications to Object Detection},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We discuss a formulation for active example selection for function learning problems. This formulation is obtained by adapting Fedorov's optimal experiment design to the learning problem. We specifically show how to analytically derive example selection algorithms for certain well defined function classes. We then explore the behavior and sample complexity of such active learning algorithms. Finally, we view object detection as a special case of function learning and show how our formulation reduces to a useful heuristic to choose examples to reduce the generalization error.},
 month        = {jun~6},
 number       = {CBCL-116},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1438.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1438.pdf},
}

@techreport{CBCL-127,
 author       = {Athanassios G. Siapas David C. Somers, Emanuel V. Todorov and Sur, Mriganka},
 title        = {Vector-Based Integration of Local and Long-Range Information in Visual Cortex},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Integration of inputs by cortical neurons provides the basis for the complex information processing performed in the cerebral cortex. Here, we propose a new analytic framework for understanding integration within cortical neuronal receptive fields. Based on the synaptic organization of cortex, we argue that neuronal integration is a systems{\textendash}level process better studied in terms of local cortical circuitry than at the level of single neurons, and we present a method for constructing self-contained modules which capture (nonlinear) local circuit interactions. In this framework, receptive field elements naturally have dual (rather than the traditional unitary influence since they drive both excitatory and inhibitory cortical neurons. This vector-based analysis, in contrast to scalarsapproaches, greatly simplifies integration by permitting linear summation of inputs from both ''classical'' and ''extraclassical'' receptive field regions. We illustrate this by explaining two complex visual cortical phenomena, which are incompatible with scalar notions of neuronal integration.},
 month        = {jan~18},
 number       = {CBCL-127},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1556.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1556.pdf},
}

@techreport{CBCL-128,
 author       = {Jones, Tomaso Poggio Michael J.},
 title        = {Model-Based Matching of Line Drawings by Linear Combinations of Prototypes},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We describe a technique for finding pixelwise correspondences between two images by using models of objects of the same class to guide the search. The object models are 'learned' from example images (also called prototypes) of an object class. The models consist of a linear combination ofsprototypes. The flow fields giving pixelwise correspondences between a base prototype and each of the other prototypes must be given. A novel image of an object of the same class is matched to a model by minimizing an error between the novel image and the current guess for the closest modelsimage. Currently, the algorithm applies to line drawings of objects. An extension to real grey level images is discussed.},
 month        = {jan~18},
 number       = {CBCL-128},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1559.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1559.pdf},
}

@techreport{CBCL-129,
 author       = {Jaakkola, Lawrence K. Saul Tommi S. and Jordan, Michael I.},
 title        = {Fast Learning by Bounding Likelihoods in Sigmoid Type Belief Networks},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Sigmoid type belief networks, a class of probabilistic neural networks, provide a natural framework for compactly representing probabilistic information in a variety of unsupervised and supervised learning problems. Often the parameters used in these networks need to be learned from examples. Unfortunately, estimating the parameters via exact probabilistic calculations (i.e, the EM-algorithm) is intractable even for networks with fairly small numbers of hidden units. We propose to avoid the infeasibility of the E step by bounding likelihoods instead of computing them exactly. We introduce extended and complementary representations for these networks and show that the estimation of the network parameters can be made fast (reduced to quadratic optimization) by performing the estimation in either of the alternative domains. The complementary networks can be used for continuous density estimation as well.},
 month        = {feb~9},
 number       = {CBCL-129},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1560.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1560.pdf},
}

@techreport{CBCL-130,
 author       = {Ghahramani, Zoubin and Jordan, Michael I.},
 title        = {Factorial Hidden Markov Models},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present a framework for learning in hidden Markov models with distributed state representations. Within this framework, we derive a learning algorithm based on the Expectation{\textendash}Maximization (EM) procedure for maximum likelihood estimation. Analogous to the standard Baum-Welch update rules, the M-step of our algorithm is exact and can be solved analytically. However, due to the combinatorial nature of the hidden state representation, the exact E-step is intractable. A simple and tractable mean field approximation is derived. Empirical results on a set of problems suggest that both the mean field approximation and Gibbs sampling are viable alternatives to the computationally expensive exact algorithm.},
 month        = {feb~9},
 number       = {CBCL-130},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1561.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1561.pdf},
}

@techreport{CBCL-131,
 author       = {Jordan, Michael I. and Bishop, Christopher M.},
 title        = {Neural Networks},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present an overview of current research on artificial neural networks, emphasizing a statistical perspective. We view neural networks as parameterized graphs that make probabilistic assumptions about data, and view learning algorithms as methods for finding parameter values that look probable in the light of the data. We discuss basic issues in representation and learning, and treat some of the practical issues that arise in fitting networks to data. We also discuss links between neural networks and the general formalism of graphical models.},
 month        = {mar~13},
 number       = {CBCL-131},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1562.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1562.pdf},
}

@techreport{CBCL-132,
 author       = {Smyth, David Heckerman Padhraic and Jordan, Michael},
 title        = {Probabilistic Independence Networks for Hidden Markov Probability Models},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Graphical techniques for modeling the dependencies of randomvariables have been explored in a variety of different areas includingstatistics, statistical physics, artificial intelligence, speech recognition, image processing, and genetics.Formalisms for manipulating these models have been developedrelatively independently in these research communities. In this paper weexplore hidden Markov models (HMMs) and related structures within the general framework of probabilistic independencenetworks (PINs). The paper contains a self-contained review of the basic principles of PINs.It is shown that the well- known forward-backward (F-B) and Viterbialgorithms for HMMs are special cases of more general inference algorithms forarbitrary PINs. Furthermore, the existence of inference and estimationalgorithms for more general graphical models provides a set of analysistools for HMM practitioners who wish to explore a richer class of HMMstructures.Examples of relatively complex models to handle sensorfusion and coarticulationin speech recognitionare introduced and treated within the graphical model framework toillustrate the advantages of the general approach.},
 month        = {mar~13},
 number       = {CBCL-132},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1565.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1565.pdf},
}

@techreport{CBCL-137,
 author       = {Ulrich Sauerland Douglas A. Jones, Robert C. Berwick, Franklin Cho Zeeshan Khan Karen T. Kohl Naoyuki Nomura Anand Radhakrishnan and Ulicny, Brian},
 title        = {Verb Classes and Alternations in Bangla, German, English, and Korean},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In this report, we investigate the relationship between the semantic and syntactic properties of verbs. Our work is based on the English Verb Classes and Alternations of (Levin, 1993). We explore how these classes are manifested in other languages, in particular, in Bangla, German, and Korean. Our report includes a survey and classification of several hundred verbs from these languages into the cross-linguistic equivalents of Levin's classes. We also explore ways in which our findings may be used to enhance WordNet in two ways: making the English syntactic information of WordNet more fine-grained, and making WordNet multilingual.},
 month        = {may~6},
 number       = {CBCL-137},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1517.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1517.pdf},
}

@techreport{CBCL-138,
 author       = {Olshausen, Bruno A.},
 title        = {Learning Linear, Sparse, Factorial Codes},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In previous work (Olshausen     Field 1996), an algorithm was described for learning linear sparse codes which, when trained on natural images, produces a set of basis functions that are spatially localized, oriented, and bandpass (i.e., wavelet-like). This note shows how the algorithm may be interpreted within a maximum-likelihood framework. Several useful insights emerge from this connection: it makes explicit the relation to statistical independence (i.e., factorial coding), it shows a formal relationship to the algorithm of Bell and Sejnowski (1995), and it suggests how to adapt parameters that were previously fixed.},
 month        = {dec~2},
 number       = {CBCL-138},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1580.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1580.pdf},
}

@techreport{CBCL-139,
 author       = {Jones, Michael J. and Poggio, Tomaso},
 title        = {Model-Based Matching by Linear Combinations of Prototypes},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We describe a method for modeling object classes (such as faces) using 2D example images and an algorithm for matching a model to a novel image. The object class models are ''learned'' from example images that we call prototypes. In addition to the images, the pixelwise correspondences between a reference prototype and each of the other prototypes must also be provided. Thus a model consists of a linear combination of prototypical shapes and textures. A stochastic gradient descent algorithm is used to match a model to a novel image by minimizing the error between the model and the novel image. Example models are shown as well as example matches to novel images. The robustness of the matching algorithm is also evaluated. The technique can be used for a number of applications including the computation of correspondence between novel images of a certain known class, object recognition, image synthesis and image compression.},
 month        = {dec~2},
 number       = {CBCL-139},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1583.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1583.pdf},
}

@techreport{CBCL-140,
 author       = {Evgeniou, Theodoros},
 title        = {Image Based Rendering Using Algebraic Techniques},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper presents an image-based rendering system using algebraic relations between different views of an object. The system uses pictures of an object taken from known positions. Given three such images it can generate ''virtual'' ones as the object would look from any position near the ones that the two input images were taken from. The extrapolation from the example images can be up to about 60 degrees of rotation. The system is based on the trilinear constraints that bind any three view so fan object. As a side result, we propose two new methods for camera calibration. We developed and used one of them. We implemented the system and tested it on real images of objects and faces. We also show experimentally that even when only two images taken from unknown positions are given, the system can be used to render the object from other view points as long as we have a good estimate of the internal parameters of the camera used and we are able to find good correspondence between the example images. In addition, we present the relation between these algebraic constraints and a factorization method for shape and motion estimation. As a result we propose a method for motion estimation in the special case of orthographic projection.},
 month        = {nov~2},
 number       = {CBCL-140},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1592.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1592.pdf},
}

@techreport{CBCL-141,
 author       = {Lemm, Joerg C.},
 title        = {Prior Information and Generalized Questions},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In learning problems available information is usually divided into two categories: examples of function values (or training data) and prior information (e.g. a smoothness constraint). This paper 1.) studies aspects on which these two categories usually differ, like their relevance for generalization and their role in the loss function, 2.) presents a unifying formalism, where both types of information are identified with answers to generalized questions, 3.) shows what kind of generalized information is necessary to enable learning, 4.) aims to put usual training data and prior information on a more equal footing by discussing possibilities and variants of measurement and control for generalized questions, including the examples of smoothness and symmetries, 5.) reviews shortly the measurement of linguistic concepts based on fuzzy priors, and principles to combine preprocessors, 6.) uses a Bayesian decision theoretic framework, contrasting parallel and inverse decision problems, 7.) proposes, for problems with non{\textendash}approximation aspects, a Bayesian two step approximation consisting of posterior maximization and a subsequent risk minimization, 8.) analyses empirical risk minimization under the aspect of nonlocal information 9.) compares the Bayesian two step approximation with empirical risk minimization, including their interpretations of Occam's razor, 10.) formulates examples of stationarity conditions for the maximum posterior approximation with nonlocal and nonconvex priors, leading to inhomogeneous nonlinear equations, similar for example to equations in scattering theory in physics. In summary, this paper focuses on the dependencies between answers to different questions. Because not training examples alone but such dependencies enable generalization, it emphasizes the need of their empirical measurement and control and of a more explicit treatment in theory.},
 month        = {dec~2},
 number       = {CBCL-141},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1598.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1598.pdf},
}

@techreport{CBCL-142,
 author       = {T. Poggio B. Schoelkopf, K. Sung, C. Burges F. Girosi P. Niyogi and Vapnik, V.},
 title        = {Comparing Support Vector Machines with Gaussian Kernels to Radial Basis Function Classifiers},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The Support Vector (SV) machine is a novel type of learning machine, based on statistical learning theory, which contains polynomial classifiers, neural networks, and radial basis function (RBF) networks as special cases. In the RBF case, the SV algorithm automatically determines centers, weights and threshold such as to minimize an upper bound on the expected test error. The present study is devoted to an experimental comparison of these machines with a classical approach, where the centers are determined by $k${\textendash} means clustering and the weights are found using error backpropagation. We consider three machines, namely a classical RBF machine, an SV machine with Gaussian kernel, and a hybrid system with the centers determined by the SV method and the weights trained by error backpropagation. Our results show that on the US postal service database of handwritten digits, the SV machine achieves the highest test accuracy, followed by the hybrid approach. The SV approach is thus not only theoretically well{\textendash}founded, but also superior in a practical application.},
 month        = {dec~2},
 number       = {CBCL-142},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1599.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1599.pdf},
}

@techreport{CBCL-143,
 author       = {Vetter, Michael J. Jones Thomas and Poggio, Tomaso},
 title        = {A Bootstrapping Algorithm for Learning Linear Models of Object Classes},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Flexible models of object classes, based on linear combinations of prototypical images, are capable of matching novel images of the same class and have been shown to be a powerful tool to solve several fundamental vision tasks such as recognition, synthesis and correspondence. The key problem in creating a specific flexible model is the computation of pixelwise correspondence between the prototypes, a task done until now in a semiautomatic way. In this paper we describe an algorithm that automatically bootstraps the correspondence between the prototypes. The algorithm - which can be used for 2D images as well as for 3D models - is shown to synthesize successfully a flexible model of frontal face images and a flexible model of handwritten digits.},
 month        = {mar~2},
 number       = {CBCL-143},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1600.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1600.pdf},
}

@techreport{CBCL-144,
 author       = {Osuna, Robert Freund Edgar and Girosi, Federico},
 title        = {Support Vector Machines},
 subtitle     = {Training and Applications},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The Support Vector Machine (SVM) is a new and very promising classification technique developed by Vapnik and his group at AT   T Bell Labs. This new learning algorithm can be seen as an alternative training technique for Polynomial, Radial Basis Function and Multi- Layer Perceptron classifiers. An interesting property of this approach is that it is an approximate implementation of the Structural Risk Minimization (SRM) induction principle. The derivation of Support Vector Machines, its relationship with SRM, and its geometrical insight, are discussed in this paper. Training a SVM is equivalent to solve a quadratic programming problem with linear and box constraints in a number of variables equal to the number of data points. When the number of data points exceeds few thousands the problem is very challenging, because the quadratic form is completely dense, so the memory needed to store the problem grows with the square of the number of data points. Therefore, training problems arising in some real applications with large data sets are impossible to load into memory, and cannot be solved using standard non-linear constrained optimization algorithms. We present a decomposition algorithm that can be used to train SVM's over large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of, and also establish the stopping criteria for the algorithm. We present previous approaches, as well as results and important details of our implementation of the algorithm using a second-order variant of the Reduced Gradient Method as the solver of the sub- problems. As an application of SVM's, we present preliminary results we obtained applying SVM to the problem of detecting frontal human faces in real images.},
 month        = {mar~2},
 number       = {CBCL-144},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1602.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1602.pdf},
}

@techreport{CBCL-145,
 author       = {Amnon Shashua Shai Avidan, Theodoros Evgeniou and Poggio, Tomaso},
 title        = {Image-Based View Synthesis},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present a new method for rendering novel images of flexible 3D objects from a small number of example images in correspondence. The strength of the method is the ability to synthesize images whose viewing position is significantly far away from the viewing cone of the example images (''view extrapolation''), yet without ever modeling the 3D structure of the scene. The method relies on synthesizing a chain of ''trilinear tensors'' that governs the warping function from the example images to the novel image, together with a multi-dimensional interpolation function that synthesizes the non-rigid motions of the viewed object from the virtual camera position. We show that two closely spaced example images alone are sufficient in practice to synthesize a significant viewing cone, thus demonstrating the ability of representing an object by a relatively small number of model images {\textemdash} for the purpose of cheap and fast viewers that can run on standard hardware.},
 month        = {jan~2},
 number       = {CBCL-145},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1603.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1603.pdf},
}

@techreport{CBCL-146,
 author       = {Meila, Marina and Jordan, Michael I.},
 title        = {Triangulation by Continuous Embedding},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {When triangulating a belief network we aim to obtain a junction tree of minimum state space. Searching for the optimal triangulation can be cast as a search over all the permutations of the network's vaeriables. Our approach is to embed the discrete set of permutations in a convex continuous domain D. By suitably extending the cost function over D and solving the continous nonlinear optimization task we hope to obtain a good triangulation with respect to the aformentioned cost. In this paper we introduce an upper bound to the total junction tree weight as the cost function. The appropriatedness of this choice is discussed and explored by simulations. Then we present two ways of embedding the new objective function into continuous domains and show that they perform well compared to the best known heuristic.},
 month        = {mar~27},
 number       = {CBCL-146},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1605.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1605.pdf},
}

@techreport{CBCL-147,
 author       = {Girosi, Federico},
 title        = {An Equivalence Between Sparse Approximation and Support Vector Machines},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In the first part of this paper we show a similarity between the principle of Structural Risk Minimization Principle (SRM) (Vapnik, 1982) and the idea of Sparse Approximation, as defined in (Chen, Donoho and Saunders, 1995) and Olshausen and Field (1996). Then we focus on two specific (approximate) implementations of SRM and Sparse Approximation, which have been used to solve the problem of function approximation. For SRM we consider the Support Vector Machine technique proposed by V. Vapnik and his team at AT   T Bell Labs, and for Sparse Approximation we consider a modification of the Basis Pursuit De-Noising algorithm proposed by Chen, Donoho and Saunders (1995). We show that, under certain conditions, these two techniques are equivalent: they give the same solution and they require the solution of the same quadratic programming problem.},
 month        = {may~27},
 number       = {CBCL-147},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1606.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1606.pdf},
}

@techreport{CBCL-148,
 author       = {Geiger, Gad and Lettvin, Jerome Y.},
 title        = {A View on Dyslexia},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We describe here, briefly, a perceptual non- reading measure which reliably distinguishes between dyslexic persons and ordinary readers. More importantly, we describe a regimen of practice with which dyslexics learn a new perceptual strategy for reading. Two controlled experiment on dyslexics children demonstrate the regimen's efficiency.},
 month        = {jun~27},
 number       = {CBCL-148},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1608.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1608.pdf},
}

@techreport{CBCL-150,
 author       = {Dill, Marcus and Edelman, Shimon},
 title        = {Translation Invariance in Object Recognition, and Its Relation to Other Visual Transformations},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Human object recognition is generally considered to tolerate changes of the stimulus position in the visual field. A number of recent studies, however, have cast doubt on the completeness of translation invariance. In a new series of experiments we tried to investigate whether positional specificity of short-term memory is a general property of visual perception. We tested same/different discrimination of computer graphics models that were displayed at the same or at different locations of the visual field, and found complete translation invariance, regardless of the similarity of the animals and irrespective of direction and size of the displacement (Exp. 1 and 2). Decisions were strongly biased towards same decisions if stimuli appeared at a constant location, while after translation subjects displayed a tendency towards different decisions. Even if the spatial order of animal limbs was randomized (''scrambled animals''), no deteriorating effect of shifts in the field of view could be detected (Exp. 3). However, if the influence of single features was reduced (Exp. 4 and 5) small but significant effects of translation could be obtained. Under conditions that do not reveal an influence of translation, rotation in depth strongly interferes with recognition (Exp. 6). Changes of stimulus size did not reduce performance (Exp. 7). Tolerance to these object transformations seems to rely on different brain mechanisms, with translation and scale invariance being achieved in principle, while rotation invariance is not.},
 month        = {jun~27},
 number       = {CBCL-150},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1610.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1610.pdf},
}

@techreport{CBCL-151,
 author       = {Meila, Michael I. Jordan Marina and Morris, Quaid},
 title        = {Estimating Dependency Structure as a Hidden Variable},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper introduces a probability model, the mixture of trees that can account for sparse, dynamically changing dependence relationships. We present a family of efficient algorithms that use EMand the Minimum Spanning Tree algorithm to find the ML and MAP mixtureof trees for a variety of priors, including the Dirichlet and the MDL priors.},
 month        = {jun~27},
 number       = {CBCL-151},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1611.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1611.pdf},
}

@techreport{CBCL-152,
 author       = {Pontil, Massimiliano and Verri, Alessandro},
 title        = {Properties of Support Vector Machines},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Support Vector Machines (SVMs) perform pattern recognition between two point classes by finding a decision surface determined by certain points of the training set, termed Support Vectors (SV). This surface, which in some feature space of possibly infinite dimension can be regarded as a hyperplane, is obtained from the solution of a problem of quadratic programming that depends on a regularization parameter. In this paper we study some mathematical properties of support vectors and show that the decision surface can be written as the sum of two orthogonal terms, the first depending only on the margin vectors (which are SVs lying on the margin), the second proportional to the regularization parameter. For almost all values of the parameter, this enables us to predict how the decision surface varies for small parameter changes. In the special but important case of feature space of finite dimension m, we also show that there are at most m+1 margin vectors and observe that m+1 SVs are usually sufficient to fully determine the decision surface. For relatively small m this latter result leads to a consistent reduction of the SV number.},
 month        = {aug~27},
 number       = {CBCL-152},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1612.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1612.pdf},
}

@techreport{CBCL-153,
 author       = {Li, Zhaoping},
 title        = {Visual Segmentation without Classification in a Model of the Primary Visual Cortex},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Stimuli outside classical receptive fields significantly influence the neurons' activities in primary visual cortex. We propose that such contextual influences are used to segment regions by detecting the breakdown of homogeneity or translation invariance in the input, thus computing global region boundaries using local interactions. This is implemented in a biologically based model of V1, and demonstrated in examples of texture segmentation and figure-ground segregation. By contrast with traditional approaches, segmentation occurs without classification or comparison of features within or between regions and is performed by exactly the same neural circuit responsible for the dual problem of the grouping and enhancement of contours.},
 month        = {aug~27},
 number       = {CBCL-153},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1613.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1613.pdf},
}

@techreport{CBCL-154,
 author       = {Edelman, Shimon and Duvdevani-Bar, Sharon},
 title        = {Visual Recognition and Categorization on the Basis of Similarities to Multiple Class Prototypes},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {To recognize a previously seen object, the visual system must overcome the variability in the object's appearance caused by factors such as illumination and pose. Developments in computer vision suggest that it may be possible to counter the influence of these factors, by learning to interpolate between stored views of the target object, taken under representative combinations of viewing conditions. Daily life situations, however, typically require categorization, rather than recognition, of objects. Due to the open-ended character both of natural kinds and of artificial categories, categorization cannot rely on interpolation between stored examples. Nonetheless, knowledge of several representative members, or prototypes, of each of the categories of interest can still provide the necessary computational substrate for the categorization of new instances. The resulting representational scheme based on similarities to prototypes appears to be computationally viable, and is readily mapped onto the mechanisms of biological vision revealed by recent psychophysical and physiological studies.},
 month        = {sep~27},
 number       = {CBCL-154},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1615.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1615.pdf},
}

@techreport{CBCL-155,
 author       = {Weiss, Yair},
 title        = {Belief Propagation and Revision in Networks with Loops},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Local belief propagation rules of the sort proposed by Pearl(1988) are guaranteed to converge to the optimal beliefs for singly connected networks. Recently, a number of researchers have empirically demonstrated good performance of these same algorithms on networks with loops, but a theoretical understanding of this performance has yet to be achieved. Here we lay the foundation for an understanding of belief propagation in networks with loops. For networks with a single loop, we derive ananalytical relationship between the steady state beliefs in the loopy network and the true posterior probability. Using this relationship we show a category of networks for which the MAP estimate obtained by belief update and by belief revision can be proven to be optimal (although the beliefs will be incorrect). We show how nodes can use local information in the messages they receive in order to correct the steady state beliefs. Furthermore we prove that for all networks with a single loop, the MAP estimate obtained by belief revisionat convergence is guaranteed to give the globally optimal sequence of states. The result is independent of the length of the cycle and the size of the statespace. For networks with multiple loops, we introduce the concept of a ''balanced network'' and show simulati.},
 month        = {nov~27},
 number       = {CBCL-155},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1616.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1616.pdf},
}

@techreport{CBCL-156,
 author       = {Evgeniou, Theodoros and Poggio, Tomaso},
 title        = {Sparse Representations of Multiple Signals},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We discuss the problem of finding sparse representations of a class of signals. We formalize the problem and prove it is NP-complete both in the case of a single signal and that of multiple ones. Next we develop a simple approximation method to the problem and we show experimental results using artificially generated signals. Furthermore,we use our approximation method to find sparse representations of classes of real signals, specifically of images of pedestrians. We discuss the relation between our formulation of the sparsity problem and the problem of finding representations of objects that are compact and appropriate for detection and classification.},
 month        = {sep~27},
 number       = {CBCL-156},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1619.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1619.pdf},
}

@techreport{CBCL-157,
 author       = {Stein, Gideon P. and Shashua, Amnon},
 title        = {On Degeneracy of Linear Reconstruction from Three Views},
 subtitle     = {Linear Line Complex and Applications},
 year         = {1997},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper investigates the linear degeneracies of projective structure estimation from point and line features across three views. We show that the rank of the linear system of equations for recovering the trilinear tensor of three views reduces to 23 (instead of 26) in the case when the scene is a Linear Line Complex (set of lines in space intersecting at a common line) and is 21 when the scene is planar. The LLC situation is only linearly degenerate, and we show that one can obtain a unique solution when the admissibility constraints of the tensor are accounted for. The line configuration described by an LLC, rather than being some obscure case, is in fact quite typical. It includes, as a particular example, the case of a camera moving down a hallway in an office environment or down an urban street. Furthermore, an LLC situation may occur as an artifact such as in direct estimation from spatio-temporal derivatives of image brightness. Therefore, an investigation into degeneracies and their remedy is important also in practice.},
 month        = {dec~27},
 number       = {CBCL-157},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1620.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1620.pdf},
}

@techreport{CBCL-158,
 author       = {Weiss, Yar and Adelson, Edward H.},
 title        = {Slow and Smooth},
 subtitle     = {A Bayesian Theory for the Combination of Local Motion Signals in Human Vision},
 year         = {1998},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In order to estimate the motion of an object, the visual system needs to combine multiple local measurements, each of which carries some degree of ambiguity. We present a model of motion perception whereby measurements from different image regions are combined according to a Bayesian estimator {\textemdash} the estimated motion maximizes the posterior probability assuming a prior favoring slow and smooth velocities. In reviewing a large number of previously published phenomena we find that the Bayesian estimator predicts a wide range of psychophysical results. This suggests that the seemingly complex set of illusions arise from a single computational strategy that is optimal under reasonable assumptions.},
 month        = {feb~27},
 number       = {CBCL-158},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1624.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1624.pdf},
}

@techreport{CBCL-159,
 author       = {Hofmann, Thomas and Puzicha, Jan},
 title        = {Statistical Models for Co-occurrence Data},
 year         = {1998},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Modeling and predicting co-occurrences of events is a fundamental problem of unsupervised learning. In this contribution we develop a statistical framework for analyzing co-occurrence data in a general setting where elementary observations are joint occurrences of pairs of abstract objects from two finite sets. The main challenge for statistical models in this context is to overcome the inherent data sparseness and to estimate the probabilities for pairs which were rarely observed or even unobserved in a given sample set. Moreover, it is often of considerable interest to extract grouping structure or to find a hierarchical data organization. A novel family of mixture models is proposed which explain the observed data by a finite number of shared aspects or clusters. This provides a common framework for statistical inference and structure discovery and also includes several recently proposed models as special cases. Adopting the maximum likelihood principle, EM algorithms are derived to fit the model parameters. We develop improved versions of EM which largely avoid overfitting problems and overcome the inherent locality of EM{\textendash}based optimization. Among the broad variety of possible applications, e.g., in information retrieval, natural language processing, data mining, and computer vision, we have chosen document retrieval, the statistical analysis of noun/adjective co-occurrence and the unsupervised segmentation of textured images to test and evaluate the proposed algorithms.},
 month        = {feb~27},
 number       = {CBCL-159},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1625.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1625.pdf},
}

@techreport{CBCL-160,
 author       = {Riesenhuber, Maximilian and Poggio, Tomaso},
 title        = {Modeling Invariances in Inferotemporal Cell Tuning},
 year         = {1998},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In macaque inferotemporal cortex (IT), neurons have been found to respond selectively to complex shapes while showing broad tuning (''invariance'') with respect to stimulus transformations such as translation and scale changes and a limited tuning to rotation in depth. Training monkeys with novel, paperclip-like objects, Logothetis et al. could investigate whether these invariance properties are due to experience with exhaustively many transformed instances of an object or if there are mechanisms that allow the cells to show response invariance also to previously unseen instances of that object. They found object-selective cells in anterior IT which exhibited limited invariance to various transformations after training with single object views. While previous models accounted for the tuning of the cells for rotations in depth and for their selectivity to a specific object relative to a population of distractor objects, the model described here attempts to explain in a biologically plausible way the additional properties of translation and size invariance. Using the same stimuli as in the experiment, we find that model IT neurons exhibit invariance properties which closely parallel those of real neurons. Simulations show that the model is capable of unsupervised learning of view-tuned neurons. The model also allows to make experimentally testable predictions regarding novel stimulus transformations and combinations of stimuli.},
 month        = {mar~27},
 number       = {CBCL-160},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1629.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1629.pdf},
}

@techreport{CBCL-161,
 author       = {Poggio, Tomaso and Girosi, Federico},
 title        = {Notes on PCA, Regularization, Sparsity and Support Vector Machines},
 year         = {1998},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We derive a new representation for a function as a linear combination of local correlation kernels at optimal sparse locations and discuss its relation to PCA, regularization, sparsity principles and Support Vector Machines. We first review previous results for the approximation of a function from discrete data (Girosi, 1998) in the context of Vapnik''s feature space and dual representation (Vapnik, 1995). We apply them to show 1) that a standard regularization functional with a stabilizer defined in terms of the correlation function induces a regression function in the span of the feature space of classical Principal Components and 2) that there exist a dual representations of the regression function in terms of a regularization network with a kernel equal to a generalized correlation function. We then describe the main observation of the paper: the dual representation in terms of the correlation function can be sparsified using the Support Vector Machines (Vapnik, 1982) technique and this operation is equivalent to sparsify a large dictionary of basis functions adapted to the task, using a variation of Basis Pursuit De-Noising (Chen, Donoho and Saunders, 1995; see also related work by Donahue and Geiger, 1994; Olshausen and Field, 1995; Lewicki and Sejnowski, 1998). In addition to extending the close relations between regularization, Support Vector Machines and sparsity, our work also illuminates and formalizes the LFA concept of Penev and Atick (1996). We discuss the relation between our results, which are about regression, and the different problem of pattern classification.},
 month        = {may~27},
 number       = {CBCL-161},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1632.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1632.pdf},
}

@techreport{CBCL-162,
 author       = {Papgeorgiou, Federico Girosi Constantine P. and Poggio, Tomaso},
 title        = {Sparse Correlation Kernel Analysis and Reconstruction},
 year         = {1998},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper presents a new paradigm for signal reconstruction and superresolution, Correlation Kernel Analysis (CKA), that is based on the selection of a sparse set of bases from a large dictionary of class- specific basis functions. The basis functions that we use are the correlation functions of the class of signals we are analyzing. To choose the appropriate features from this large dictionary, we use Support Vector Machine (SVM) regression and compare this to traditional Principal Component Analysis (PCA) for the tasks of signal reconstruction, superresolution, and compression. The testbed we use in this paper is a set of images of pedestrians. This paper also presents results of experiments in which we use a dictionary of multiscale basis functions and then use Basis Pursuit De-Noising to obtain a sparse, multiscale approximation of a signal. The results are analyzed and we conclude that 1) when used with a sparse representation technique, the correlation function is an effective kernel for image reconstruction and superresolution, 2) for image compression, PCA and SVM have different tradeoffs, depending on the particular metric that is used to evaluate the results, 3) in sparse representation techniques, L\_1 is not a good proxy for the true measure of sparsity, L\_0, and 4) the L\_epsilon norm may be a better error metric for image reconstruction and compression than the L\_2 norm, though the exact psychophysical metric should take into account high order structure in images.},
 month        = {may~27},
 number       = {CBCL-162},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1635.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1635.pdf},
}

@techreport{CBCL-163,
 author       = {Li, Zhaoping},
 title        = {Pre-Attentive Segmentation in the Primary Visual Cortex},
 year         = {1998},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Stimuli outside classical receptive fields have been shown to exert significant influence over the activities of neurons in primary visual cortexWe propose that contextual influences are used for pre-attentive visual segmentation, in a new framework called segmentation without classification. This means that segmentation of an image into regions occurs without classification of features within a region or comparison of features between regions. This segmentation framework is simpler than previous computational approaches, making it implementable by V1 mechanisms, though higher leve l visual mechanisms are needed to refine its output. However, it easily handles a class of segmentation problems that are tricky in conventional methods. The cortex computes global region boundaries by detecting the breakdown of homogeneity or translation invariance in the input, using local intra-cortical interactions mediated by the horizontal connections. The difference between contextual influences near and far from region boundaries makes neural activities near region boundaries higher than elsewhere, making boundaries more salient for perceptual pop-out. This proposal is implemented in a biologically based model of V1, and demonstrated using examples of texture segmentation and figure-ground segregation. The model performs segmentation in exactly the same neural circuit that solves the dual problem of the enhancement of contours, as is suggested by experimental observations. Its behavior is compared with psychophysical and physiological data on segmentation, contour enhancement, and contextual influences. We discuss the implications of segmentation without classification and the predictions of our V1 model, and relate it to other phenomena such as asymmetry in visual search.},
 month        = {jun~30},
 number       = {CBCL-163},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1640.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1640.pdf},
}

@techreport{CBCL-164,
 author       = {Andrew Lo Nicholas Chan, Blake LeBaron and Poggio, Tomaso},
 title        = {Information Dissemination and Aggregation in Asset Markets with Simple Intelligent Traders},
 year         = {1998},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Various studies of asset markets have shown that traders are capable of learning and transmitting information through prices in many situations. In this paper we replace human traders with intelligent software agents in a series of simulated markets. Using these simple learning agents, we are able to replicate several features of the experiments with human subjects, regarding (1) dissemination of information from informed to uninformed traders, and (2) aggregation of information spread over different traders.},
 month        = {sep~11},
 number       = {CBCL-164},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1646.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1646.pdf},
}

@techreport{CBCL-165,
 author       = {Meila, Michael I. Jordan Marina and Morris, Quaid},
 title        = {Estimating Dependency Structure as a Hidden Variable},
 year         = {1998},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper introduces a probability model, the mixture of trees that can account for sparse, dynamically changing dependence relationships. We present a family of efficient algorithms that use EM and the Minimum Spanning Tree algorithm to find the ML and MAP mixture of trees for a variety of priors, including the Dirichlet and the MDL priors. We also show that the single tree classifier acts like an implicit feature selector, thus making the classification performance insensitive to irrelevant attributes. Experimental results demonstrate the excellent performance of the new model both in density estimation and in classification.},
 month        = {sep~11},
 number       = {CBCL-165},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1648.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1648.pdf},
}

@techreport{CBCL-166,
 author       = {Pontil, Ryan Rifkin Massimiliano and Evgeniou, Theodoros},
 title        = {From Regression to Classification in Support Vector Machines},
 year         = {1998},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We study the relation between support vector machines (SVMs) for regression (SVMR) and SVM for classification (SVMC). We show that for a given SVMC solution there exists a SVMR solution which is equivalent for a certain choice of the parameters. In particular our result is that for $epsilon$ sufficiently close to one, the optimal hyperplane and threshold for the SVMC problem with regularization parameter C\_c are equal to (1-epsilon){\textasciicircum}- 1 times the optimal hyperplane and threshold for SVMR with regularization parameter C\_r = (1-epsilon)C\_c. A direct consequence of this result is that SVMC can be seen as a special case of SVMR.},
 month        = {nov~11},
 number       = {CBCL-166},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1649.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1649.pdf},
}

@techreport{CBCL-167,
 author       = {Shelton, Christian R.},
 title        = {Three-Dimensional Correspondence},
 year         = {1998},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper describes the problem of three-dimensional object correspondence and presents an algorithm for matching two three-dimensional colored surfaces using polygon reduction and the minimization of an energy function. At the core of this algorithm is a novel data-dependent multi-resolution pyramid for polygonal surfaces. The algorithm is general to correspondence between any two manifolds of the same dimension embedded in a higher dimensional space. Results demonstrating correspondences between various objects are presented and a method for incorporating user input is also detailed.},
 month        = {dec~11},
 number       = {CBCL-167},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AITR-1650.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AITR-1650.pdf},
}

@techreport{CBCL-168,
 author       = {Pontil, Sayan Mukherjee Massimiliano and Girosi, Federico},
 title        = {On the Noise Model of Support Vector Machine Regression},
 year         = {1998},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Support Vector Machines Regression (SVMR) is a regression technique which has been recently introduced by V. Vapnik and his collaborators (Vapnik, 1995; Vapnik, Golowich and Smola, 1996). In SVMR the goodness of fit is measured not by the usual quadratic loss function (the mean square error), but by a different loss function called Vapnik''s $epsilon$- insensitive loss function, which is similar to the ''robust'' loss functions introduced by Huber (Huber, 1981). The quadratic loss function is well justified under the assumption of Gaussian additive noise. However, the noise model underlying the choice of Vapnik's loss function is less clear. In this paper the use of Vapnik's loss function is shown to be equivalent to a model of additive and Gaussian noise, where the variance and mean of the Gaussian are random variables. The probability distributions for the variance and mean will be stated explicitly. While this work is presented in the framework of SVMR, it can be extended to justify non-quadratic loss functions in any Maximum Likelihood or Maximum A Posteriori approach. It applies not only to Vapnik's loss function, but to a much broader class of loss functions.},
 month        = {oct~11},
 number       = {CBCL-168},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1651.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1651.pdf},
}

@techreport{CBCL-170,
 author       = {Mukherjee, Sayan and Vapnik, Vladimir},
 title        = {Multivariate Density Estimation},
 subtitle     = {An SVM Approach},
 year         = {1999},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We formulate density estimation as an inverse operator problem. We then use convergence results of empirical distribution functions to true distribution functions to develop an algorithm for multivariate density estimation. The algorithm is based upon a Support Vector Machine (SVM) approach to solving inverse operator problems. The algorithm is implemented and tested on simulated data from different distributions and different dimensionalities, gaussians and laplacians in $R^2$ and $R^12$. A comparison in performance is made with Gaussian Mixture Models (GMMs). Our algorithm does as well or better than the GMMs for the simulations tested and has the added advantage of being automated with respect to parameters.},
 month        = {apr~11},
 number       = {CBCL-170},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1653.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1653.pdf},
}

@techreport{CBCL-171,
 author       = {Evgeniou, Massimiliano Pontil Theodoros and Poggio, Tomaso},
 title        = {A Unified Framework for Regularization Networks and Support Vector Machines},
 year         = {1999},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Regularization Networks and Support Vector Machines are techniques for solving certain problems of learning from examples {\textendash} in particular the regression problem of approximating a multivariate function from sparse data. We present both formulations in a unified framework, namely in the context of Vapnik's theory of statistical learning which provides a general foundation for the learning problem, combining functional analysis and statistics.},
 month        = {mar~11},
 number       = {CBCL-171},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1654.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1654.pdf},
}

@techreport{CBCL-172,
 author       = {Evgeniou, Theodoros and Pontil, Massimiliano},
 title        = {On the V(subscript gamma) Dimension for Regression in Reproducing Kernel Hilbert Spaces},
 year         = {1999},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper presents a computation of the $V_gamma$ dimension for regression in bounded subspaces of Reproducing Kernel Hilbert Spaces (RKHS) for the Support Vector Machine (SVM) regression $epsilon$-insensitive loss function, and general $L_p$ loss functions. Finiteness of the $RV_gamma$ dimension is shown, which also proves uniform convergence in probability for regression machines in RKHS subspaces that use the $L_epsilon$ or general $L_p$ loss functions. This paper presenta a novel proof of this result also for the case that a bias is added to the functions in the RKHS.},
 month        = {may~11},
 number       = {CBCL-172},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1656.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1656.pdf},
}

@techreport{CBCL-173,
 author       = {Ezzat, Tony and Poggio, Tomaso},
 title        = {Visual Speech Synthesis by Morphing Visemes},
 year         = {1999},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present MikeTalk, a text-to-audiovisual speech synthesizer which converts input text into an audiovisual speech stream. MikeTalk is built using visemes, which are a small set of images spanning a large range of mouth shapes. The visemes are acquired from a recorded visual corpus of a human subject which is specifically designed to elicit one instantiation of each viseme. Using optical flow methods, correspondence from every viseme to every other viseme is computed automatically. By morphing along this correspondence, a smooth transition between viseme images may be generated. A complete visual utterance is constructed by concatenating viseme transitions. Finally, phoneme and timing information extracted from a text-to-speech synthesizer is exploited to determine which viseme transitions to use, and the rate at which the morphing process should occur. In this manner, we are able to synchronize the visual speech stream with the audio speech stream, and hence give the impression of a photorealistic talking face.},
 month        = {may~11},
 number       = {CBCL-173},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1658.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1658.pdf},
}

@techreport{CBCL-177,
 author       = {Rifkin, Massimiliano Pontil Ryan and Verri, Alessandro},
 title        = {A Note on Support Vector Machines Degeneracy},
 year         = {1999},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {When training Support Vector Machines (SVMs) over non-separable data sets, one sets the threshold $b$ using any dual cost coefficient that is strictly between the bounds of $0$ and $C$. We show that there exist SVM training problems with dual optimal solutions with all coefficients at bounds, but that all such problems are degenerate in the sense that the "optimal separating hyperplane" is given by $f w = f 0$, and the resulting (degenerate) SVM will classify all future points identically (to the class that supplies more training data). We also derive necessary and sufficient conditions on the input data for this to occur. Finally, we show that an SVM training problem can always be made degenerate by the addition of a single data point belonging to a certain unboundedspolyhedron, which we characterize in terms of its extreme points and rays.},
 month        = {aug~11},
 number       = {CBCL-177},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1661.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1661.pdf},
}

@techreport{CBCL-178,
 author       = {Mohan, Anuj},
 title        = {Object Detection in Images by Components},
 year         = {1999},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In this paper we present a component based person detection system that is capable of detecting frontal, rear and near side views of people, and partially occluded persons in cluttered scenes. The framework that is described here for people is easily applied to other objects as well. The motivation for developing a component based approach is two fold: first, to enhance the performance of person detection systems on frontal and rear views of people and second, to develop a framework that directly addresses the problem of detecting people who are partially occluded or whose body parts blend in with the background. The data classification is handled by several support vector machine classifiers arranged in two layers. This architecture is known as Adaptive Combination of Classifiers (ACC). The system performs very well and is capable of detecting people even when all components of a person are not found. The performance of the system is significantly better than a full body person detector designed along similar lines. This suggests that the improved performance is due to the components based approach and the ACC data classification structure.},
 month        = {aug~11},
 number       = {CBCL-178},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1664.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1664.pdf},
}

@techreport{CBCL-179,
 author       = {Kumar, Vinay P. and Poggio, Tomaso},
 title        = {Learning-Based Approach to Real Time Tracking and Analysis of Faces},
 year         = {1999},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper describes a trainable system capable of tracking faces and facialsfeatures like eyes and nostrils and estimating basic mouth features such as sdegrees of openness and smile in real time. In developing this system, we have addressed the twin issues of image representation and algorithms for learning. We have used the invariance properties of image representations based on Haar wavelets to robustly capture various facial features. Similarly, unlike previous approaches this system is entirely trained using examples and does not rely on a priori (hand-crafted) models of facial features based on optical flow or facial musculature. The system works in several stages that begin with face detection, followed by localization of facial features and estimation of mouth parameters. Each of these stages is formulated as a problem in supervised learning from examples. We apply the new and robust technique of support vector machines (SVM) for classification in the stage of skin segmentation, face detection and eye detection. Estimation of mouth parameters is modeled as a regression from a sparse subset of coefficients (basis functions) of an overcomplete dictionary of Haar wavelets.},
 month        = {sep~23},
 number       = {CBCL-179},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1672.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1672.pdf},
}

@techreport{CBCL-180,
 author       = {Papageorgiou, Constantine P. and Poggio, Tomaso},
 title        = {A Trainable Object Detection System},
 subtitle     = {Car Detection in Static Images},
 year         = {1999},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper describes a general, trainable architecture for object detection that has previously been applied to face and peoplesdetection with a new application to car detection in static images. Our technique is a learning based approach that uses a set of labeled training data from which an implicit model of an object class {\textendash} here, cars {\textendash} is learned. Instead of pixel representations that may be noisy and therefore not provide a compact representation for learning, our training images are transformed from pixel space to that of Haar wavelets that respond to local, oriented, multiscale intensity differences. These feature vectors are then used to train a support vector machine classifier. The detection of cars in images is an important step in applications such as traffic monitoring, driver assistance systems, and surveillance, among others. We show several examples of car detection on out-of- sample images and show an ROC curve that highlights the performance of our system.},
 month        = {oct~13},
 number       = {CBCL-180},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1673.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1673.pdf},
}

@techreport{CBCL-183,
 author       = {Riesenhuber, Maximilian and Poggio, Tomaso},
 title        = {A Note on Object Class Representation and Categorical Perception},
 year         = {1999},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present a novel scheme (''Categorical Basis Functions'', CBF) for object class representation in the brain and contrast it to the ''Chorus of Prototypes'' scheme recently proposed by Edelman. The power and flexibility of CBF is demonstrated in two examples. CBF is then applied to investigate the phenomenon of Categorical Perception, in particular the finding by Bulthoff et al. (1998) of categorization of faces by gender without corresponding Categorical Perception. Here, CBF makes predictions that can be tested in a psychophysical experiment. Finally, experiments are suggested to further test CBF.},
 month        = {dec~17},
 number       = {CBCL-183},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1679.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1679.pdf},
}

@techreport{CBCL-184,
 author       = {Evgeniou, Theodoros and Pontil, Massimiliano},
 title        = {A Note on the Generalization Performance of Kernel Classifiers with Margin},
 year         = {2000},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present distribution independent bounds on the generalization misclassification performance of a family of kernel classifiers with margin. Support Vector Machine classifiers (SVM) stem out of this class of machines. The bounds are derived through computations of the $V_gamma$ dimension of a family of loss functions where the SVM one belongs to. Bounds that use functions of margin distributions (i.e. functions of the slack variables of SVM) are derived.},
 month        = {may~1},
 number       = {CBCL-184},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1681.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1681.pdf},
}

@techreport{CBCL-185,
 author       = {Riesenhuber, Maximilian and Poggio, Tomaso},
 title        = {The Individual is Nothing, the Class Everything},
 subtitle     = {Psychophysics and Modeling of Recognition in Obect Classes},
 year         = {2000},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Most psychophysical studies of object recognition have focussed on the recognition and representation of individual objects subjects had previously explicitely been trained on. Correspondingly, modeling studies have often employed a 'grandmother'-type representation where the objects to be recognized were represented by individual units. However, objects in the natural world are commonly members of a class containing a number of visually similar objects, such as faces, for which physiology studies have provided support for a representation based on a sparse population code, which permits generalization from the learned exemplars to novel objects of that class. In this paper, we present results from psychophysical and modeling studies intended to investigate object recognition in natural ('continuous') object classes. In two experiments, subjects were trained to perform subordinate level discrimination in a continuous object class - images of computer-rendered cars - created using a 3D morphing system. By comparing the recognition performance of trained and untrained subjects we could estimate the effects of viewpoint-specific training and infer properties of the object class-specific representation learned as a result of training. We then compared the experimental findings to simulations, building on our recently presented HMAX model of object recognition in cortex, to investigate the computational properties of a population-based object class representation as outlined above. We find experimental evidence, supported by modeling results, that training builds a viewpoint- and class-specific representation that supplements a pre-existing repre-sentation with lower shape discriminability but possibly greater viewpoint invariance.},
 month        = {may~1},
 number       = {CBCL-185},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1682.ps; ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1682.pdf},
}

@techreport{CBCL-186,
 author       = {Papageorgiou, Constantine P.},
 title        = {A Trainable System for Object Detection in Images and Video Sequences},
 year         = {2000},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This thesis presents a general, trainable system for object detection in static images and video sequences. The core system finds a certain class of objects in static images of completely unconstrained, cluttered scenes without using motion, tracking, or handcrafted models and without making any assumptions on the scene structure or the number of objects in the scene. The system uses a set of training data of positive and negative example images as input, transforms the pixel images to a Haar wavelet representation, and uses a support vector machine classifier to learn the difference between in-class and out-of-class patterns. To detect objects in out-of-sample images, we do a brute force search over all the subwindows in the image. This system is applied to face, people, and car detection with excellent results. For our extensions to video sequences, we augment the core static detection system in several ways {\textendash} 1) extending the representation to five frames, 2) implementing an approximation to a Kalman filter, and 3) modeling detections in an image as a density and propagating this density through time according to measured features. In addition, we present a real-time version of the system that is currently running in a DaimlerChrysler experimental vehicle. As part of this thesis, we also present a system that, instead of detecting full patterns, uses a component-based approach. We find it to be more robust to occlusions, rotations in depth, and severe lighting conditions for people detection than the full body version. We also experiment with various other representations including pixels and principal components and show results that quantify how the number of features, color, and gray-level affect performance.},
 month        = {may~1},
 number       = {CBCL-186},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AITR-1685.ps; ftp://publications.ai.mit.edu/ai-publications/1500-1999/AITR-1685.pdf},
}

@techreport{CBCL-187,
 author       = {Heisele, Tomaso Poggio Bernd and Pontil, Massimiliano},
 title        = {Face Detection in Still Gray Images},
 year         = {2000},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present a trainable system for detecting frontal and near-frontal views of faces in still gray images using Support Vector Machines (SVMs). We first consider the problem of detecting the whole face pattern by a single SVM classifer. In this context we compare different types of image features, present and evaluate a new method for reducing the number of features and discuss practical issues concerning the parameterization of SVMs and the selection of training data. The second part of the paper describes a component-based method for face detection consisting of a two-level hierarchy of SVM classifers. On the first level, component classifers independently detect components of a face, such as the eyes, the nose, and the mouth. On the second level, a single classifer checks if the geometrical configuration of the detected components in the image matches a geometrical model of a face.},
 month        = {may~7},
 number       = {CBCL-187},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1687.ps; ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1687.pdf},
}

@techreport{CBCL-188,
 author       = {Bernd Heisele Chikahito Nakajima, Massimiliano Pontil and Poggio, Tomaso},
 title        = {People Recognition in Image Sequences by Supervised Learning},
 year         = {2000},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We describe a system that learns from examples to recognize people in images taken indoors. Images of people are represented by color-based and shape-based features. Recognition is carried out through combinations of Support Vector Machine classifiers (SVMs). Different types of multiclass strategies based on SVMs are explored and compared to k-Nearest Neighbors classifiers (kNNs). The system works in real time and shows high performance rates for people recognition throughout one day.},
 month        = {jun~7},
 number       = {CBCL-188},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1688.ps; ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1688.pdf},
}

@techreport{CBCL-190,
 author       = {Riesenhuber, Maximilian and Poggio, Tomaso},
 title        = {Computational Models of Object Recognition in Cortex},
 subtitle     = {A Review},
 year         = {2000},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Understanding how biological visual systems perform object recognition is one of the ultimate goals in computational neuroscience. Among the biological models of recognition the main distinctions are between feedforward and feedback and between object-centered and view-centered. From a computational viewpoint the different recognition tasks - for instance categorization and identification - are very similar, representing different trade-offs between specificity and invariance. Thus the different tasks do not strictly require different classes of models. The focus of the review is on feedforward, view-based models that are supported by psychophysical and physiological data.},
 month        = {aug~7},
 number       = {CBCL-190},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1695.ps; ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1695.pdf},
}

@techreport{CBCL-191,
 author       = {Kumar, Vinay and Poggio, Tomaso},
 title        = {Learning-Based Approach to Estimation of Morphable Model Parameters},
 year         = {2000},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We describe the key role played by partial evaluation in the Supercomputing Toolkit, a parallel computing system for scientific applications that effectively exploits the vast amount of parallelism exposed by partial evaluation. The Supercomputing Toolkit parallel processor and its associated partial evaluation-based compiler have been used extensively by scientists at MIT, and have made possible recent results in astrophysics showing that the motion of the planets in our solar system is chaotically unstable.},
 month        = {sep~1},
 number       = {CBCL-191},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1696.ps; ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1696.pdf},
}

@techreport{CBCL-192,
 author       = {Sayan Mukherjee Thomas Serre, Bernd Heisele and Poggio, Tomaso},
 title        = {Feature Selection for Face Detection},
 year         = {2000},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present a new method to select features for a face detection system using Support Vector Machines (SVMs). In the first step we reduce the dimensionality of the input space by projecting the data into a subset of eigenvectors. The dimension of the subset is determined by a classification criterion based on minimizing a bound on the expected error probability of an SVM. In the second step we select features from the SVM feature space by removing those that have low contributions to the decision function of the SVM.},
 month        = {sep~20},
 number       = {CBCL-192},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1697.ps; ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1697.pdf},
}

@techreport{CBCL-193,
 author       = {Alvira, Mariano and Rifkin, Ryan},
 title        = {An Empirical Comparison of SNoW and SVMs for Face Detection},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Impressive claims have been made for the performance of the SNoW algorithm on face detection tasks by Yang et. al. [7]. In particular, by looking at both their results and those of Heisele et. al. [3], one could infer that the SNoW system performed substantially better than an SVM-based system, even when the SVM used a polynomial kernel and the SNoW system used a particularly simplistic 'primitive' linear representation. We evaluated the two approaches in a controlled experiment, looking directly at performance on a simple, fixed-sized test set, isolating out 'infrastructure' issues related to detecting faces at various scales in large images. We found that SNoW performed about as well as linear SVMs, and substantially worse than polynomial SVMs.},
 month        = {jan~17},
 number       = {CBCL-193},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-004.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-004.pdf},
}

@techreport{CBCL-194,
 author       = {Shelton, Christian R.},
 title        = {Policy Improvement for POMDPs Using Normalized Importance Sampling},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present a new method for estimating the expected return of a POMDP from experience. The estimator does not assume any knowle ge of the POMDP and allows the experience to be gathered with an arbitrary set of policies. The return is estimated for any new policy of the POMDP. We motivate the estimator from function-approximation and importance sampling points-of-view and derive its theoretical properties. Although the estimator is biased, it has low variance and the bias is often irrelevant when the estimator is used for pair-wise comparisons.We conclude by extending the estimator to policies with memory and compare its performance in a greedy search algorithm to the REINFORCE algorithm showing an order of magnitude reduction in the number of trials required.},
 month        = {mar~20},
 number       = {CBCL-194},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-002.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-002.pdf},
}

@techreport{CBCL-195,
 author       = {Chan, Nicholas Tung and Shelton, Christian},
 title        = {An Electronic Market-Maker},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper presents an adaptive learning model for market-making under the reinforcement learning framework. Reinforcement learning is a learning technique in which agents aim to maximize the long-term accumulated rewards. No knowledge of the market environment, such as the order arrival or price process, is assumed. Instead, the agent learns from real-time market experience and develops explicit market-making strategies, achieving multiple objectives including the maximizing of profits and minimization of the bid-ask spread. The simulation results show initial success in bringing learning techniques to building market-making algorithms.},
 month        = {apr~17},
 number       = {CBCL-195},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-005.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-005.pdf},
}

@techreport{CBCL-196,
 author       = {Sadr, Javid and Sinha, Pawan},
 title        = {Exploring Object Perception with Random Image Structure Evolution},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We have developed a technique called RISE (Random Image Structure Evolution), by which one may systematically sample continuous paths in a high-dimensional image space. A basic RISE sequence depicts the evolution of an object's image from a random field, along with the reverse sequence which depicts the transformation of this image back into randomness. The processing steps are designed to ensure that important low-level image attributes such as the frequency spectrum and luminance are held constant throughout a RISE sequence. Experiments based on the RISE paradigm can be used to address some key open issues in object perception. These include determining the neural substrates underlying object perception, the role of prior knowledge and expectation in object perception, and the developmental changes in object perception skills from infancy to adulthood.},
 month        = {mar~30},
 number       = {CBCL-196},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-006.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-006.pdf},
}

@techreport{CBCL-197,
 author       = {Ho, Purdy},
 title        = {Rotation Invariant Real-time Face Detection and Recognition System},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In this report, a face recognition system that is capable of detecting and recognizing frontal and rotated faces was developed. Two face recognition methods focusing on the aspect of pose invariance are presented and evaluated - the whole face approach and the component-based approach. The main challenge of this project is to develop a system that is able to identify faces under different viewing angles in realtime. The development of such a system will enhance the capability and robustness of current face recognition technology. The whole-face approach recognizes faces by classifying a single feature vector consisting of the gray values of the whole face image. The component-based approach first locates the facial components and extracts them. These components are normalized and combined into a single feature vector for classification. The Support Vector Machine (SVM) is used as the classifier for both approaches. Extensive tests with respect to the robustness against pose changes are performed on a database that includes faces rotated up to about 40 degrees in depth. The component-based approach clearly outperforms the whole-face approach on all tests. Although this approach isproven to be more reliable, it is still too slow for real-time applications. That is the reason why a real-time face recognition system using the whole-face approach is implemented to recognize people in color video sequences.},
 month        = {may~31},
 number       = {CBCL-197},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-010.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-010.pdf},
}

@techreport{CBCL-198,
 author       = {T. Poggio, S. Mukherjee, R. Rifkin A. Rakhlin and Verri, A.},
 title        = {b},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In this note we characterize the role of b ,which is the constant in the standard form of the solution provided by the Support Vector Machine technique f (x )= i =1 i K (x ,x i )+b .},
 month        = {jul~25},
 number       = {CBCL-198},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-011.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-011.pdf},
}

@techreport{CBCL-199,
 author       = {Alvira, Jim Paris Mariano and Rifkin, Ryan},
 title        = {The Audiomomma Music Recommendation System},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We design and implement a system that recommends musicians to listeners. The basic idea is to keep track of what artists a user listens to, to find other users with similar tastes, and to recommend other artists that these similar listeners enjoy. The system utilizes a client-server architecture, a web-based interface, and an SQL database to store and process information. We describe Audiomomma-0.3, a proof-of-concept implementation of the above ideas.},
 month        = {jul~25},
 number       = {CBCL-199},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-012.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-012.pdf},
}

@techreport{CBCL-200,
 author       = {Andrew W. Lo Nicholas T. Chan, Ely Dahan and Poggio, Tomaso},
 title        = {Experimental Markets for Product Concepts},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Market prices are well known to efficiently collect and aggregate diverse information regarding the value of commodities and assets. The role of markets has been particularly suitable to pricing financial securities. This article provides an alternative application of the pricing mechanism to marketing research - using pseudo-securities markets to measure preferences over new product concepts. Surveys, focus groups, concept tests and conjoint studies are methods traditionally used to measure individual and aggregate preferences. Unfortunately, these methods can be biased, costly and time-consuming to conduct. The present research is motivated by the desire to efficiently measure preferences and more accurately predict new product success, based on the efficiency and incentive-compatibility of security trading markets. The article describes a novel market research method, pro-vides insight into why the method should work, and compares the results of several trading experiments against other methodologies such as concept testing and conjoint analysis.},
 month        = {jul~25},
 number       = {CBCL-200},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-013.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-013.pdf},
}

@techreport{CBCL-201,
 author       = {Russell, Richard and Sinha, Pawan},
 title        = {Perceptually-based Comparison of Image Similarity Metrics},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The image comparison operation {\textendash} assessing how well one image matches another {\textendash} forms a critical component of many image analysis systems and models of human visual processing. Two norms used commonly for this purpose are L1 and L2, which are specific instances of the Minkowski metric. However, there is often not a principled reason for selecting one norm over the other. One way to address this problem is by examining whether one metric better captures the perceptual notion of image similarity than the other. With this goal, we examined perceptual preferences for images retrieved on the basis of the L1 versus the L2 norm. These images were either small fragments without recognizable content, or larger patterns with recognizable content created via vector quantization. In both conditions the subjects showed a consistent preference for images matched using the L1 metric. These results suggest that, in the domain of natural images of the kind we have used, the L1 metric may better capture human notions of image similarity.},
 month        = {jul~25},
 number       = {CBCL-201},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-014.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-014.pdf},
}

@techreport{CBCL-202,
 author       = {Torralba, Pawan Sinha Antonio},
 title        = {Recognizing Indoor Scenes},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We propose a scheme for indoor place identification based on the recognition of global scene views. Scene views are encoded using a holistic representation that provides low-resolution spatial and spectral information. The holistic nature of the representation dispenses with the need to rely on specific objects or local landmarks and also renders it robust against variations in object configurations. We demonstrate the scheme on the problem of recognizing scenes in video sequences captured while walking through an office environment. We develop a method for distinguishing between 'diagnostic' and 'generic' views and also evaluate changes in system performances as a function of the amount of training data available and the complexity of the representation.},
 month        = {jul~25},
 number       = {CBCL-202},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-015.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-015.pdf},
}

@techreport{CBCL-203,
 author       = {Sinha, Pawan and Torralba, Antonio},
 title        = {Role of Low-level Mechanisms in Brightness Perception},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Brightness judgments are a key part of the primate brain`s visual analysis of the environment. There is general consensus that the perceived brightness of an image region is based not only on its actual luminance, but also on the photometric structure of its neighborhood. However, it is unclear precisely how a region`s context influences its perceived brightness. Recent research has suggested that brightness estimation may be based on a sophisticated analysis of scene layout in terms of transparency, illumination and shadows. This work has called into question the role of low-level mechanisms, such as lateral inhibition, as explanations for brightness phenomena. Here we describe experiments with displays for which low-level and high-level analyses make qualitatively different predictions, and with which we can quantitatively assess the trade-offs between low-level and high-level factors. We find that brightness percepts in these displays are governed by low-level stimulus properties, even when these percepts are inconsistent with higher-level interpretations of scene layout. These results point to the important role of low-level mechanisms in determining brightness percepts.},
 month        = {aug~25},
 number       = {CBCL-203},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-017.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-017.pdf},
}

@techreport{CBCL-204,
 author       = {Shelton, Christian Robert},
 title        = {Importance Sampling for Reinforcement Learning with Multiple Objectives},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This thesis considers three complications that arise from applying reinforcement learning to a real-world application. In the process of using reinforcement learning to build an adaptive electronic market-maker, we find the sparsity of data, the partial observability of the domain, and the multiple objectives of the agent to cause serious problems for existing reinforcement learning algorithms. We employ importance sampling (likelihood ratios) to achieve good performance in partially observable Markov decision processes with few data. Our importance sampling estimator requires no knowledge about the environment and places few restrictions on the method of collecting data. It can be used efficiently with reactive controllers, finite-state controllers, or policies with function approximation. We present theoretical analyses of the estimator and incorporate it into a reinforcement learning algorithm. Additionally, this method provides a complete return surface which can be used to balance multiple objectives dynamically. We demonstrate the need for multiple goals in a variety of applications and natural solutions based on our sampling method. The thesis concludes with example results from employing our algorithm to the domain of automated electronic market-making.},
 month        = {aug~17},
 number       = {CBCL-204},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AITR-2001-003.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AITR-2001-003.pdf},
}

@techreport{CBCL-205,
 author       = {Torralba, Antonio and Sinha, Pawan},
 title        = {Contextual Priming for Object Detection},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {There is general consensus that context can be a rich source of information about an object's identity, location and scale. In fact, the structure of many real-world scenes is governed by strong configurational rules akin to those that apply to a single object. Here we introduce a simple probabilistic framework for modeling the relationship between context and object properties based on the correlation between the statistics of low-level features across the entire scene and the objects that it contains. The resulting scheme serves as an effective procedure for object priming, context driven focus of attention and automatic scale-selection on real-world scenes.},
 month        = {sep~5},
 number       = {CBCL-205},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-020.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-020.pdf},
}

@techreport{CBCL-206,
 author       = {Yeo, Tomaso Poggio Gene},
 title        = {Multiclass Classification of SRBCTs},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {A novel approach to multiclass tumor classification using Artificial Neural Networks (ANNs) was introduced in a recent paper citeKhan2001. The method successfully classified and diagnosed small, round blue cell tumors (SRBCTs) of childhood into four distinct categories, neuroblastoma (NB), rhabdomyosarcoma (RMS), non-Hodgkin lymphoma (NHL) and the Ewing family of tumors (EWS), using cDNA gene expression profiles of samples that included both tumor biopsy material and cell lines. We report that using an approach similar to the one reported by Yeang et al citeYeang2001, i.e. multiclass classification by combining outputs of binary classifiers, we achieved equal accuracy with much fewer features. We report the performances of 3 binary classifiers (k-nearest neighbors (kNN), weighted-voting (WV), and support vector machines (SVM)) with 3 feature selection techniques (Golub's Signal to Noise (SN) ratios citeGolub99, Fisher scores (FSc) and Mukherjee's SVM feature selection (SVMFS))citeSayan98.},
 month        = {aug~25},
 number       = {CBCL-206},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-018.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-018.pdf},
}

@techreport{CBCL-207,
 author       = {Yu, Martin A. Giese Angela J. and Poggio, Tomaso A.},
 title        = {Biologically Plausible Neural Circuits for Realization of Maximum Operations},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Object recognition in the visual cortex is based on a hierarchical architecture, in which specialized brain regions along the ventral pathway extract object features of increasing levels of complexity, accompanied by greater invariance in stimulus size, position, and orientation. Recent theoretical studies postulate a non-linear pooling function, such as the maximum (MAX) operation could be fundamental in achieving such invariance. In this paper, we are concerned with neurally plausible mechanisms that may be involved in realizing the MAX operation. Four canonical circuits are proposed, each based on neural mechanisms that have been previously discussed in the context of cortical processing. Through simulations and mathematical analysis, we examine the relative performance and robustness of these mechanisms. We derive experimentally verifiable predictions for each circuit and discuss their respective physiological considerations.},
 month        = {sep~5},
 number       = {CBCL-207},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-022.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-022.pdf},
}

@techreport{CBCL-208,
 author       = {Torralba, Antonio and Sinha, Pawan},
 title        = {Detecting Faces in Impoverished Images},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The ability to detect faces in images is of critical ecological significance. It is a pre-requisite for other important face perception tasks such as person identification, gender classification and affect analysis. Here we address the question of how the visual system classifies images into face and non-face patterns. We focus on face detection in impoverished images, which allow us to explore information thresholds required for different levels of performance. Our experimental results provide lower bounds on image resolution needed for reliable discrimination between face and non-face patterns and help characterize the nature of facial representations used by the visual system under degraded viewing conditions. Specifically, they enable an evaluation of the contribution of luminance contrast, image orientation and local context on face-detection performance.},
 month        = {nov~5},
 number       = {CBCL-208},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-028.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-028.pdf},
}

@techreport{CBCL-209,
 author       = {Ostrovsky, Patrick Cavanagh Yuri and Sinha, Pawan},
 title        = {Perceiving Illumination Inconsistencies in Scenes},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The human visual system is adept at detecting and encoding statistical regularities in its spatio-temporal environment. Here we report an unexpected failure of this ability in the context of perceiving inconsistencies in illumination distributions across a scene. Contrary to predictions from previous studies [Enns and Rensink, 1990; Sun and Perona, 1996a, 1996b, 1997], we find that the visual system displays a remarkable lack of sensitivity to illumination inconsistencies, both in experimental stimuli and in images of real scenes. Our results allow us to draw inferences regarding how the visual system encodes illumination distributions across scenes. Specifically, they suggest that the visual system does not verify the global consistency of locally derived estimates of illumination direction.},
 month        = {nov~5},
 number       = {CBCL-209},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-029.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-029.pdf},
}

@techreport{CBCL-210,
 author       = {Rennie, Jason D. M. and Rifkin, Ryan},
 title        = {Improving Multiclass Text Classification with the Support Vector Machine},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We compare Naive Bayes and Support Vector Machines on the task of multiclass text classification. Using a variety of approaches to combine the underlying binary classifiers, we find that SVMs substantially outperform Naive Bayes. We present full multiclass results on two well-known text data sets, including the lowest error to date on both data sets. We develop a new indicator of binary performance to show that the SVM's lower multiclass error is a result of its improved binary performance. Furthermore, we demonstrate and explore the surprising result that one-vs-all classification performs favorably compared to other approaches even though it has no error-correcting properties.},
 month        = {oct~16},
 number       = {CBCL-210},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-026.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-026.pdf},
}

@techreport{CBCL-211,
 author       = {Riesenhuber, Maximilian},
 title        = {Generalization over contrast and mirror reversal, but not figure-ground reversal, in an ''edge-based},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Baylis     Driver (Nature Neuroscience, 2001) have recently presented data on the response of neurons in macaque inferotemporal cortex (IT) to various stimulus transformations. They report that neurons can generalize over contrast and mirror reversal, but not over figure-ground reversal. This finding is taken to demonstrate that {\textquotedblleft}the selectivity of IT neurons is not determined simply by the distinctive contours in a display, contrary to simple edge-based models of shape recognition'', citing our recently presented model of object recognition in cortex (Riesenhuber     Poggio, Nature Neuroscience, 1999). In this memo, I show that the main effects of the experiment can be obtained by performing the appropriate simulations in our simple feedforward model. This suggests for IT cell tuning that the possible contributions of explicit edge assignment processes postulated in (Baylis     Driver, 2001) might be smaller than expected.},
 month        = {dec~10},
 number       = {CBCL-211},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-034.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-034.pdf},
}

@techreport{CBCL-212,
 author       = {Yip, Andrew and Sinha, Pawan},
 title        = {Role of color in face recognition},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {One of the key challenges in face perception lies in determining the contribution of different cues to face identification. In this study, we focus on the role of color cues. Although color appears to be a salient attribute of faces, past research has suggested that it confers little recognition advantage for identifying people. Here we report experimental results suggesting that color cues do play a role in face recognition and their contribution becomes evident when shape cues are degraded. Under such conditions, recognition performance with color images is significantly better than that with grayscale images. Our experimental results also indicate that the contribution of color may lie not so much in providing diagnostic cues to identity as in aiding low-level image-analysis processes such as segmentation.},
 month        = {dec~13},
 number       = {CBCL-212},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-035.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-035.pdf},
}

@techreport{CBCL-213,
 author       = {Torralba, Antonio and Oliva, Aude},
 title        = {Global Depth Perception from Familiar Scene Structure},
 year         = {2001},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In the absence of cues for absolute depth measurements as binocular disparity, motion, or defocus, the absolute distance between the observer and a scene cannot be measured. The interpretation of shading, edges and junctions may provide a 3D model of the scene but it will not inform about the actual ''size'' of the space. One possible source of information for absolute depth estimation is the image size of known objects. However, this is computationally complex due to the difficulty of the object recognition process. Here we propose a source of information for absolute depth estimation that does not rely on specific objects: we introduce a procedure for absolute depth estimation based on the recognition of the whole scene. The shape of the space of the scene and the structures present in the scene are strongly related to the scale of observation. We demonstrate that, by recognizing the properties of the structures present in the image, we can infer the scale of the scene, and therefore its absolute mean depth. We illustrate the interest in computing the mean depth of the scene with application to scene recognition and object detection.},
 month        = {dec~10},
 number       = {CBCL-213},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-036.ps; ftp://publications.ai.mit.edu/ai-publications/2001/AIM-2001-036.pdf},
}

@techreport{CBCL-214,
 author       = {Sayan Mukherjee Tomaso Poggio, Ryan Rifkin and Rakhlin, Alex},
 title        = {Bagging Regularizes},
 year         = {2002},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Intuitively, we expect that averaging {\textemdash} or bagging {\textemdash} different regressors with low correlation should smooth their behavior and be somewhat similar to regularization. In this note we make this intuition precise. Using an almost classical definition of stability, we prove that a certain form of averaging provides generalization bounds with a rate of convergence of the same order as Tikhonov regularization {\textemdash} similar to fashionable RKHS- based learning algorithms.},
 month        = {mar~15},
 number       = {CBCL-214},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-003.ps; ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-003.pdf},
}

@techreport{CBCL-215,
 author       = {Knoblich, Ulf and Riesenhuber, Maximilan},
 title        = {Stimulus Simplification and Object Representation},
 subtitle     = {A Modeling Study},
 year         = {2002},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Tsunoda et al. (2001) recently studied the nature of object representation in monkey inferotemporal cortex using a combination of optical imaging and extracellular recordings. In particular, they examined IT neuron responses to complex natural objects and ''simplified'' versions thereof. In that study, in 42},
 month        = {mar~15},
 number       = {CBCL-215},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-004.ps; ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-004.pdf},
}

@techreport{CBCL-216,
 author       = {Knoblich, David J. Freedman Ulf and Riesenhuber, Maximilian},
 title        = {Categorization in IT and PFC},
 subtitle     = {Model and Experiments},
 year         = {2002},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In a recent experiment, Freedman et al. recorded from inferotemporal (IT) and prefrontal cortices (PFC) of monkeys performing a ''cat/dog'' categorization task (Freedman 2001 and Freedman, Riesenhuber, Poggio, Miller 2001). In this paper we analyze the tuning properties of view-tuned units in our HMAX model of object recognition in cortex (Riesenhuber 1999) using the same paradigm and stimuli as in the experiment. We then compare the simulation results to the monkey inferotemporal neuron population data. We find that view-tuned model IT units that were trained without any explicit category information can show category-related tuning as observed in the experiment. This suggests that the tuning properties of experimental IT neurons might primarily be shaped by bottom-up stimulus-space statistics, with little influence of top-down task-specific information. The population of experimental PFC neurons, on the other hand, shows tuning properties that cannot be explained just by stimulus tuning. These analyses are compatible with a model of object recognition in cortex (Riesenhuber 2000) in which a population of shape-tuned neurons provides a general basis for neurons tuned to different recognition tasks.},
 month        = {apr~18},
 number       = {CBCL-216},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-007.ps; ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-007.pdf},
}

@techreport{CBCL-217,
 author       = {Kim, Adlar J. and Shelton, Christian R.},
 title        = {Modeling Stock Order Flows and Learning Market-Making from Data},
 year         = {2002},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Stock markets employ specialized traders, market-makers, designed to provide liquidity and volume to the market by constantly supplying both supply and demand. In this paper, we demonstrate a novel method for modeling the market as a dynamic system and a reinforcement learning algorithm that learns profitable market-making strategies when run on this model. The sequence of buys and sells for a particular stock, the order flow, we model as an Input-Output Hidden Markov Model fit to historical data. When combined with the dynamics of the order book, this creates a highly non-linear and difficult dynamic system. Our reinforcement learning algorithm, based on likelihood ratios, is run on this partially-observable environment. We demonstrate learning results for two separate real stocks.},
 month        = {jun~22},
 number       = {CBCL-217},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-009.ps; ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-009.pdf},
}

@techreport{CBCL-218,
 author       = {Schneider, Robert and Riesenhuber, Maximilian},
 title        = {A Detailed Look at Scale and Translation Invariance in a Hierarchical Neural Model of Visual Object Recognition},
 year         = {2002},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The HMAX model has recently been proposed by Riesenhuber     Poggio as a hierarchical model of position- and size-invariant object recognition in visual cortex. It has also turned out to model successfully a number of other properties of the ventral visual stream (the visual pathway thought to be crucial for object recognition in cortex), and particularly of (view- tuned) neurons in macaque inferotemporal cortex, the brain area at the top of the ventral stream. The original modeling study only used {\textquotedblleft}paperclip'' stimuli, as in the corresponding physiology experiment, and did not explore systematically how model units' invariance properties depended on model parameters. In this study, we aimed at a deeper understanding of the inner workings of HMAX and its performance for various parameter settings and {\textquotedblleft}natural'' stimulus classes. We examined HMAX responses for different stimulus sizes and positions systematically and found a dependence of model units' responses on stimulus position for which a quantitative description is offered. Interestingly, we find that scale invariance properties of hierarchical neural models are not independent of stimulus class, as opposed to translation invariance, even though both are affine transformations within the image plane.},
 month        = {aug~5},
 number       = {CBCL-218},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-011.ps; ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-011.pdf},
}

@techreport{CBCL-219,
 author       = {Giese, Martin Alexander and Poggio, Tomaso},
 title        = {Biologically Plausible Neural Model for the Recognition of Biological Motion and Actions},
 year         = {2002},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The visual recognition of complex movements and actions is crucial for communication and survival in many species. Remarkable sensitivity and robustness of biological motion perception have been demonstrated in psychophysical experiments. In recent years, neurons and cortical areas involved in action recognition have been identified in neurophysiological and imaging studies. However, the detailed neural mechanisms that underlie the recognition of such complex movement patterns remain largely unknown. This paper reviews the experimental results and summarizes them in terms of a biologically plausible neural model. The model is based on the key assumption that action recognition is based on learned prototypical patterns and exploits information from the ventral and the dorsal pathway. The model makes specific predictions that motivate new experiments.},
 month        = {aug~5},
 number       = {CBCL-219},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-012.ps; ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-012.pdf},
}

@techreport{CBCL-220,
 author       = {Giese, M. A. and Xie, X.},
 title        = {Exact Solution of the Nonlinear Dynamics of Recurrent Neural Mechanisms for Direction Selectivity},
 year         = {2002},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Different theoretical models have tried to investigate the feasibility of recurrent neural mechanisms for achieving direction selectivity in the visual cortex. The mathematical analysis of such models has been restricted so far to the case of purely linear networks. We present an exact analytical solution of the nonlinear dynamics of a class of direction selective recurrent neural models with threshold nonlinearity. Our mathematical analysis shows that such networks have form-stable stimulus-locked traveling pulse solutions that are appropriate for modeling the responses of direction selective cortical neurons. Our analysis shows also that the stability of such solutions can break down giving raise to a different class of solutions (''lurching activity waves'') that are characterized by a specific spatio-temporal periodicity. These solutions cannot arise in models for direction selectivity with purely linear spatio-temporal filtering.},
 month        = {aug~5},
 number       = {CBCL-220},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-013.ps; ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-013.pdf},
}

@techreport{CBCL-221,
 author       = {Kumar, Vinay P.},
 title        = {Towards Man-Machine Interfaces},
 subtitle     = {Combining Top-down Constraints with Bottom-up Learning in Facial Analysis},
 year         = {2002},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This thesis proposes a methodology for the design of man-machine interfaces by combining top-down and bottom-up processes in vision. From a computational perspective, we propose that the scientific-cognitive question of combining top- down and bottom-up knowledge is similar to the engineering question of labeling a training set in a supervised learning problem. We investigate these questions in the realm of facial analysis. We propose the use of a linear morphable model (LMM) for representing top-down structure and use it to model various facial variations such as mouth shapes and expression, the pose of faces and visual speech (visemes). We apply a supervised learning method based on support vector machine (SVM) regression for estimating the parameters of LMMs directly from pixel-based representations of faces. We combine these methods for designing new, more self- contained systems for recognizing facial expressions, estimating facial pose and for recognizing visemes.},
 month        = {sep~22},
 number       = {CBCL-221},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2002/AITR-2002-008.ps; ftp://publications.ai.mit.edu/ai-publications/2002/AITR-2002-008.pdf},
}

@techreport{CBCL-222,
 author       = {Perez-Breva, Luis and Yoshimi, Osamu},
 title        = {Model Selection in Summary Evaluation},
 year         = {2002},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {A difficulty in the design of automated text summarization algorithms is in the objective evaluation. Viewing summarization as a tradeoff between length and information content, we introduce a technique based on a hierarchy of classifiers to rank, through model selection, different summarization methods. This summary evaluation technique allows for broader comparison of summarization methods than the traditional techniques of summary evaluation. We present an empirical study of two simple, albeit widely used, summarization methods that shows the different usages of this automated task-based evaluation system and confirms the results obtained with human-based evaluation methods over smaller corpora.},
 month        = {dec~5},
 number       = {CBCL-222},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-023.ps; ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-023.pdf},
}

@techreport{CBCL-223,
 author       = {Tomaso Poggio Sayan Mukherjee, Partha Niyogi and Rifkin, Ryan},
 title        = {Statistical Learning},
 subtitle     = {Stability is Sufficient for Generalization and Necessary and Sufficient for Consistency of Empirical Risk Minimization},
 year         = {2002},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Solutions of learning problems by Empirical Risk Minimization (ERM) need to be consistent, so that they may be predictive. They also need to be well- posed, so that they can be used robustly. We show that a statistical form of well-posedness, defined in terms of the key property of L-stability, is necessary and sufficient for consistency of ERM.},
 month        = {dec~5},
 number       = {CBCL-223},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-024.ps; ftp://publications.ai.mit.edu/ai-publications/2002/AIM-2002-024.pdf},
}

@techreport{CBCL-224,
 author       = {Geiger, Tony Ezzat Gadi and Poggio, Tomaso},
 title        = {Perceptual Evaluation of Video-Realistic Speech},
 year         = {2003},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {abstract With many visual speech animation techniques now available, there is a clear need for systematic perceptual evaluation schemes. We describe here our scheme and its application to a new video-realistic (potentially indistinguishable from real recorded video) visual-speech animation system, called Mary 101. Two types of experiments were performed: a) distinguishing visually between real and synthetic image- sequences of the same utterances, (''Turing tests'') and b) gauging visual speech recognition by comparing lip-reading performance of the real and synthetic image-sequences of the same utterances (''Intelligibility tests''). Subjects that were presented randomly with either real or synthetic image-sequences could not tell the synthetic from the real sequences above chance level. The same subjects when asked to lip-read the utterances from the same image-sequences recognized speech from real image-sequences significantly better than from synthetic ones. However, performance for both, real and synthetic, were at levels suggested in the literature on lip-reading. We conclude from the two experiments that the animation of Mary 101 is adequate for providing a percept of a talking head. However, additional effort is required to improve the animation for lip-reading purposes like rehabilitation and language learning. In addition, these two tasks could be considered as explicit and implicit perceptual discrimination tasks. In the explicit task (a), each stimulus is classified directly as a synthetic or real image-sequence by detecting a possible difference between the synthetic and the real image-sequences. The implicit perceptual discrimination task (b) consists of a comparison between visual recognition of speech of real and synthetic image-sequences. Our results suggest that implicit perceptual discrimination is a more sensitive method for discrimination between synthetic and real image-sequences than explicit perceptual discrimination.},
 month        = {feb~28},
 number       = {CBCL-224},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-003.ps; ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-003.pdf},
}

@techreport{CBCL-225,
 author       = {Jarudi, Izzat N. and Sinha, Pawan},
 title        = {Relative Contributions of Internal and External Features to Face Recognition},
 year         = {2003},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The central challenge in face recognition lies in understanding the role different facial features play in our judgments of identity. Notable in this regard are the relative contributions of the internal (eyes, nose and mouth) and external (hair and jaw-line) features. Past studies that have investigated this issue have typically used high-resolution images or good-quality line drawings as facial stimuli. The results obtained are therefore most relevant for understanding the identification of faces at close range. However, given that real-world viewing conditions are rarely optimal, it is also important to know how image degradations, such as loss of resolution caused by large viewing distances, influence our ability to use internal and external features. Here, we report experiments designed to address this issue. Our data characterize how the relative contributions of internal and external features change as a function of image resolution. While we replicated results of previous studies that have shown internal features of familiar faces to be more useful for recognition than external features at high resolution, we found that the two feature sets reverse in importance as resolution decreases. These results suggest that the visual system uses a highly non-linear cue-fusion strategy in combining internal and external features along the dimension of image resolution and that the configural cues that relate the two feature sets play an important role in judgments of facial identity.},
 month        = {mar~19},
 number       = {CBCL-225},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-004.ps; ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-004.pdf},
}

@techreport{CBCL-226,
 author       = {Das, Sanmay},
 title        = {Intelligent Market-Making in Artificial Financial Markets},
 year         = {2003},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This thesis describes and evaluates a market-making algorithm for setting prices in financial markets with asymmetric information, and analyzes the properties of artificial markets in which the algorithm is used. The core of our algorithm is a technique for maintaining an online probability density estimate of the underlying value of a stock. Previous theoretical work on market-making has led to price-setting equations for which solutions cannot be achieved in practice, whereas empirical work on algorithms for market-making has focused on sets of heuristics and rules that lack theoretical justification. The algorithm presented in this thesis is theoretically justified by results in finance, and at the same time flexible enough to be easily extended by incorporating modules for dealing with considerations like portfolio risk and competition from other market-makers. We analyze the performance of our algorithm experimentally in artificial markets with different parameter settings and find that many reasonable real-world properties emerge. For example, the spread increases in response to uncertainty about the true value of a stock, average spreads tend to be higher in more volatile markets, and market-makers with lower average spreads perform better in environments with multiple competitive market- makers. In addition, the time series data generated by simple markets populated with market-makers using our algorithm replicate properties of real-world financial time series, such as volatility clustering and the fat-tailed nature of return distributions, without the need to specify explicit models for opinion propagation and herd behavior in the trading crowd.},
 month        = {jun~19},
 number       = {CBCL-226},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2003/AITR-2003-005.ps; ftp://publications.ai.mit.edu/ai-publications/2003/AITR-2003-005.pdf},
}

@techreport{CBCL-227,
 author       = {Louie, Jennifer},
 title        = {A Biological Model of Object Recognition with Feature Learning},
 year         = {2003},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Previous biological models of object recognition in cortex have been evaluated using idealized scenes and have hard-coded features, such as the HMAX model by Riesenhuber and Poggio [10]. Because HMAX uses the same set of features for all object classes, it does not perform well in the task of detecting a target object in clutter. This thesis presents a new model that integrates learning of object-specific features with the HMAX. The new model performs better than the standard HMAX and comparably to a computer vision system on face detection. Results from experimenting with unsupervised learning of features and the use of a biologically-plausible classifier are presented.},
 month        = {jun~18},
 number       = {CBCL-227},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2003/AITR-2003-009.ps; ftp://publications.ai.mit.edu/ai-publications/2003/AITR-2003-009.pdf},
}

@techreport{CBCL-228,
 author       = {Rosen, Ezra},
 title        = {Face Representation in Cortex},
 subtitle     = {Studies Using a Simple and Not So Special Model},
 year         = {2003},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The face inversion effect has been widely documented as an effect of the uniqueness of face processing. Using a computational model, we show that the face inversion effect is a byproduct of expertise with respect to the face object class. In simulations using HMAX, a hierarchical, shape based model, we show that the magnitude of the inversion effect is a function of the specificity of the representation. Using many, sharply tuned units, an {\textquotedblleft}expert'' has a large inversion effect. On the other hand, if fewer, broadly tuned units are used, the expertise is lost, and this {\textquotedblleft}novice'' has a small inversion effect. As the size of the inversion effect is a product of the representation, not the object class, given the right training we can create experts and novices in any object class. Using the same representations as with faces, we create experts and novices for cars. We also measure the feasibility of a view-based model for recognition of rotated objects using HMAX. Using faces, we show that transfer of learning to novel views is possible. Given only one training view, the view-based model can recognize a face at a new orientation via interpolation from the views to which it had been tuned. Although the model can generalize well to upright faces, inverted faces yield poor performance because the features change differently under rotation.},
 month        = {jun~5},
 number       = {CBCL-228},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2003/AITR-2003-010.ps; ftp://publications.ai.mit.edu/ai-publications/2003/AITR-2003-010.pdf},
}

@techreport{CBCL-229,
 author       = {Balas, Pawan Sinha Benjamin J.},
 title        = {Dissociated Dipoles},
 subtitle     = {Image representation via non-local comparisons},
 year         = {2003},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {A fundamental question in visual neuroscience is how to represent image structure. The most common representational schemes rely on differential operators that compare adjacent image regions. While well-suited to encoding local relationships, such operators have significant drawbacks. Specifically, each filter`s span is confounded with the size of its sub-fields, making it difficult to compare small regions across large distances. We find that such long-distance comparisons are more tolerant to common image transformations than purely local ones, suggesting they may provide a useful vocabulary for image encoding. . We introduce the ''Dissociated Dipole,'' or ''Sticks'' operator, for encoding non-local image relationships. This operator de-couples filter span from sub-field size, enabling parametric movement between edge and region-based representation modes. We report on the perceptual plausibility of the operator, and the computational advantages of non-local encoding. Our results suggest that non-local encoding may be an effective scheme for representing image structure.},
 month        = {aug~13},
 number       = {CBCL-229},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-018.ps; ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-018.pdf},
}

@techreport{CBCL-230,
 author       = {Shimizu, Hiroaki and Poggio, Tomaso},
 title        = {Direction Estimation of Pedestrian from Images},
 year         = {2003},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The capability of estimating the walking direction of people would be useful in many applications such as those involving autonomous cars and robots. We introduce an approach for estimating the walking direction of people from images, based on learning the correct classification of a still image by using SVMs. We find that the performance of the system can be improved by classifying each image of a walking sequence and combining the outputs of the classifier. Experiments were performed to evaluate our system and estimate the trade-off between number of images in walking sequences and performance.},
 month        = {aug~27},
 number       = {CBCL-230},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-020.ps; ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-020.pdf},
}

@techreport{CBCL-231,
 author       = {Kouh, Minjoon and Riesenhuber, Maximilian},
 title        = {Investigating shape representation in area V4 with HMAX},
 subtitle     = {Orientation and Grating selectivities},
 year         = {2003},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The question of how shape is represented is of central interest to understanding visual processing in cortex. While tuning properties of the cells in early part of the ventral visual stream, thought to be responsible for object recognition in the primate, are comparatively well understood, several different theories have been proposed regarding tuning in higher visual areas, such as V4. We used the model of object recognition in cortex presented by Riesenhuber and Poggio (1999), where more complex shape tuning in higher layers is the result of combining afferent inputs tuned to simpler features, and compared the tuning properties of model units in intermediate layers to those of V4 neurons from the literature. In particular, we investigated the issue of shape representation in visual area V1 and V4 using oriented bars and various types of gratings (polar, hyperbolic, and Cartesian), as used in several physiology experiments. Our computational model was able to reproduce several physiological findings, such as the broadening distribution of the orientation bandwidths and the emergence of a bias toward non-Cartesian stimuli. Interestingly, the simulation results suggest that some V4 neurons receive input from afferents with spatially separated receptive fields, leading to experimentally testable predictions. However, the simulations also show that the stimulus set of Cartesian and non-Cartesian gratings is not sufficiently complex to probe shape tuning in higher areas, necessitating the use of more complex stimulus sets.},
 month        = {sep~8},
 number       = {CBCL-231},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-021.ps; ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-021.pdf},
}

@techreport{CBCL-232,
 author       = {Morgenstern, Bernd Heisele Christian},
 title        = {Component based recognition of objects in an office environment},
 year         = {2003},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present a component-based approach for recognizing objects under large pose changes. From a set of training images of a given object we extract a large number of components which are clustered based on the similarity of their image features and their locations within the object image. The cluster centers build an initial set of component templates from which we select a subset for the final recognizer. In experiments we evaluate different sizes and types of components and three standard techniques for component selection. The component classifiers are finally compared to global classifiers on a database of four objects.},
 month        = {nov~28},
 number       = {CBCL-232},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-024.ps; ftp://publications.ai.mit.edu/ai-publications/2003/AIM-2003-024.pdf},
}

@techreport{CBCL-233,
 author       = {Sayan Mukherjee Alexander Rakhlin, Dmitry Panchenko},
 title        = {Risk Bounds for Mixture Density Estimation},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In this paper we focus on the problem of estimating a bounded density using a finite combination of densities from a given class. We consider the Maximum Likelihood Procedure (MLE) and the greedy procedure described by Li and Barron. Approximation and estimation bounds are given for the above methods. We extend and improve upon the estimation results of Li and Barron, and in particular prove an $O(\frac1\sqrtn)$ bound on the estimation error which does not depend on the number of densities in the estimated combination.},
 month        = {jan~27},
 number       = {CBCL-233},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-001.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-001.pdf},
}

@techreport{CBCL-234,
 author       = {Lior Wolf, Amnon Shashua and Mukherjee, Sayan},
 title        = {Selecting Relevant Genes with a Spectral Approach},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Array technologies have made it possible to record simultaneously the expression pattern of thousands of genes. A fundamental problem in the analysis of gene expression data is the identification of highly relevant genes that either discriminate between phenotypic labels or are important with respect to the cellular process studied in the experiment: for example cell cycle or heat shock in yeast experiments, chemical or genetic perturbations of mammalian cell lines, and genes involved in class discovery for human tumors. In this paper we focus on the task of unsupervised gene selection. The problem of selecting a small subset of genes is particularly challenging as the datasets involved are typically characterized by a very small sample size {\textemdash} in the order of few tens of tissue samples {\textemdash} and by a very large feature space as the number of genes tend to be in the high thousands. We propose a model independent approach which scores candidate gene selections using spectral properties of the candidate affinity matrix. The algorithm is very straightforward to implement yet contains a number of remarkable properties which guarantee consistent sparse selections. To illustrate the value of our approach we applied our algorithm on five different datasets. The first consists of time course data from four well studied Hematopoietic cell lines (HL-60, Jurkat, NB4, and U937). The other four datasets include three well studied treatment outcomes (large cell lymphoma, childhood medulloblastomas, breast tumors) and one unpublished dataset (lymph status). We compared our approach both with other unsupervised methods (SOM,PCA,GS) and with supervised methods (SNR,RMB,RFE). The results clearly show that our approach considerably outperforms all the other unsupervised approaches in our study, is competitive with supervised methods and in some case even outperforms supervised approaches.},
 month        = {jan~27},
 number       = {CBCL-234},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-002.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-002.pdf},
}

@techreport{CBCL-235,
 author       = {Schneider, Robert and Riesenhuber, Maximilian},
 title        = {On the difficulty of feature-based attentional modulations in visual object recognition},
 subtitle     = {A modeling study.},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Numerous psychophysical experiments have shown an important role for attentional modulations in vision. Behaviorally, allocation of attention can improve performance in object detection and recognition tasks. At the neural level, attention increases firing rates of neurons in visual cortex whose preferred stimulus is currently attended to. However, it is not yet known how these two phenomena are linked, i.e., how the visual system could be ''tuned'' in a task-dependent fashion to improve task performance. To answer this question, we performed simulations with the HMAX model of object recognition in cortex [45]. We modulated firing rates of model neurons in accordance with experimental results about effects of feature-based attention on single neurons and measured changes in the model's performance in a variety of object recognition tasks. It turned out that recognition performance could only be improved under very limited circumstances and that attentional influences on the process of object recognition per se tend to display a lack of specificity or raise false alarm rates. These observations lead us to postulate a new role for the observed attention-related neural response modulations.},
 month        = {jan~14},
 number       = {CBCL-235},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-004.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-004.pdf},
}

@techreport{CBCL-236,
 author       = {Sinha Riesenhuber, Jarudi, Gilad},
 title        = {Face processing in humans is compatible with a simple shape-based model of vision},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Understanding how the human visual system recognizes objects is one of the key challenges in neuroscience. Inspired by a large body of physiological evidence (Felleman and Van Essen, 1991; Hubel and Wiesel, 1962; Livingstone and Hubel, 1988; Tso et al., 2001; Zeki, 1993), a general class of recognition models has emerged which is based on a hierarchical organization of visual processing, with succeeding stages being sensitive to image features of increasing complexity (Hummel and Biederman, 1992; Riesenhuber and Poggio, 1999; Selfridge, 1959). However, these models appear to be incompatible with some well-known psychophysical results. Prominent among these are experiments investigating recognition impairments caused by vertical inversion of images, especially those of faces. It has been reported that faces that differ ''featurally'' are much easier to distinguish when inverted than those that differ ''configurally'' (Freire et al., 2000; Le Grand et al., 2001; Mondloch et al., 2002) {\textendash} a finding that is difficult to reconcile with the aforementioned models. Here we show that after controlling for subjects` expectations, there is no difference between ''featurally'' and ''configurally'' transformed faces in terms of inversion effect. This result reinforces the plausibility of simple hierarchical models of object representation and recognition in cortex.},
 month        = {mar~5},
 number       = {CBCL-236},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-006.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-006.pdf},
}

@techreport{CBCL-237,
 author       = {Yokono, Jerry Jun and Poggio, Tomaso},
 title        = {Evaluation of sets of oriented and non-oriented receptive fields as local descriptors},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Local descriptors are increasingly used for the task of object recognition because of their perceived robustness with respect to occlusions and to global geometrical deformations. We propose a performance criterion for a local descriptor based on the tradeoff between selectivity and invariance. In this paper, we evaluate several local descriptors with respect to selectivity and invariance. The descriptors that we evaluated are Gaussian derivatives up to the third order, gray image patches, and Laplacian-based descriptors with either three scales or one scale filters. We compare selectivity and invariance to several affine changes such as rotation, scale, brightness, and viewpoint. Comparisons have been made keeping the dimensionality of the descriptors roughly constant. The overall results indicate a good performance by the descriptor based on a set of oriented Gaussian filters. It is interesting that oriented receptive fields similar to the Gaussian derivatives as well as receptive fields similar to the Laplacian are found in primate visual cortex.},
 month        = {mar~24},
 number       = {CBCL-237},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-007.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-007.pdf},
}

@techreport{CBCL-238,
 author       = {Yokono, Jerry Jun and Poggio, Tomaso},
 title        = {Rotation Invariant Object Recognition from One Training Example},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Local descriptors are increasingly used for the task of object recognition because of their perceived robustness with respect to occlusions and to global geometrical deformations. Such a descriptor{\textendash}based on a set of oriented Gaussian derivative filters{\textendash} is used in our recognition system. We report here an evaluation of several techniques for orientation estimation to achieve rotation invariance of the descriptor. We also describe feature selection based on a single training image. Virtual images are generated by rotating and rescaling the image and robust features are selected. The results confirm robust performance in cluttered scenes, in the presence of partial occlusions, and when the object is embedded in different backgrounds.},
 month        = {apr~27},
 number       = {CBCL-238},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-010.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-010.pdf},
}

@techreport{CBCL-239,
 author       = {Serre, Thomas and Riesenhuber, Maximilian},
 title        = {Realistic Modeling of Simple and Complex Cell Tuning in the HMAX Model, and Implications for Invariant Object Recognition in Cortex},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Riesenhuber     Poggio recently proposed a model of object recognition in cortex which, beyond integrating general beliefs about the visual system in a quantitative framework, made testable predictions about visual processing. In particular, they showed that invariant object representation could be obtained with a selective pooling mechanism over properly chosen afferents through a max operation: For instance, at the complex cells level, pooling over a group of simple cells at the same preferred orientation and position in space but at slightly different spatial frequency would provide scale tolerance, while pooling over a group of simple cells at the same preferred orientation and spatial frequency but at slightly different position in space would provide position tolerance. Indirect support for such mechanisms in the visual system come from the ability of the architecture at the top level to replicate shape tuning as well as shift and size invariance properties of {\textquotedblleft}view-tuned cells'' (VTUs) found in inferotemporal cortex (IT), the highest area in the ventral visual stream, thought to be crucial in mediating object recognition in cortex. There is also now good physiological evidence that a max operation is performed at various levels along the ventral stream. However, in the original paper by Riesenhuber     Poggio, tuning and pooling parameters of model units in early and intermediate areas were only qualitatively inspired by physiological data. In particular, many studies have investigated the tuning properties of simple and complex cells in primary visual cortex, V1. We show that units in the early levels of HMAX can be tuned to produce realistic simple and complex cell-like tuning, and that the earlier findings on the invariance properties of model VTUs still hold in this more realistic version of the model.},
 month        = {jul~27},
 number       = {CBCL-239},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-017.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-017.pdf},
}

@techreport{CBCL-240,
 author       = {James DiCarlo Gabriel Kreiman, Chou Hung, Tomaso Poggio},
 title        = {Selectivity of Local Field Potentials in Macaque Inferior Temporal Cortex},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {While single neurons in inferior temporal (IT) cortex show differential responses to distinct complex stimuli, little is known about the responses of populations of neurons in IT. We recorded single electrode data, including multi-unit activity (MUA) and local field potentials (LFP), from 618 sites in the inferior temporal cortex of macaque monkeys while the animals passively viewed 78 different pictures of complex stimuli. The LFPs were obtained by low-pass filtering the extracellular electrophysiological signal with a corner frequency of 300 Hz. As reported previously, we observed that spike counts from MUA showed selectivity for some of the pictures. Strikingly, the LFP data, which is thought to constitute an average over large numbers of neurons, also showed significantly selective responses. The LFP responses were less selective than the MUA responses both in terms of the proportion of selective sites as well as in the selectivity of each site. We observed that there was only little overlap between the selectivity of MUA and LFP recordings from the same electrode. To assess the spatial organization of selective responses, we compared the selectivity of nearby sites recorded along the same penetration and sites recorded from different penetrations. We observed that MUA selectivity was correlated on spatial scales up to 800    \#61549;m while the LFP selectivity was correlated over a larger spatial extent, with significant correlations between sites separated by several mm. Our data support the idea that there is some topographical arrangement to the organization of selectivity in inferior temporal cortex and that this organization may be relevant for the representation of object identity in IT.},
 month        = {sep~21},
 number       = {CBCL-240},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-020.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-020.pdf},
}

@techreport{CBCL-241,
 author       = {Charles Cadieu, Minjoon Kouh, Maximilian Riesenhuber and Poggio, Tomaso},
 title        = {Shape Representation in V4},
 subtitle     = {Investigating Position-Specific Tuning for Boundary Conformation with the Standard Model of Object Recognition},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The computational processes in the intermediate stages of the ventral pathway responsible for visual object recognition are not well understood. A recent physiological study by A. Pasupathy and C. Connor in intermediate area V4 using contour stimuli, proposes that a population of V4 neurons display bjectcentered, position-specific curvature tuning [18]. The ''standard model'' of object recognition, a recently developed model [23] to account for recognition properties of IT cells (extending classical suggestions by Hubel, Wiesel and others [9, 10, 19]), is used here to model the response of the V4 cells described in [18]. Our results show that a feedforward, network level mechanism can exhibit selectivity and invariance properties that correspond to the responses of the V4 cells described in [18]. These results suggest how object-centered, position-specific curvature tuning of V4 cells may arise from combinations of complex V1 cell responses. Furthermore, the model makes predictions about the responses of the same V4 cells studied by Pasupathy and Connor to novel gray level patterns, such as gratings and natural images. These predictions suggest specific experiments to further explore shape representation in V4.},
 month        = {nov~12},
 number       = {CBCL-241},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-024.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-024.pdf},
}

@techreport{CBCL-242,
 author       = {Wolf, Lior and Martin, Ian},
 title        = {Regularization Through Feature Knock Out},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In this paper, we present and analyze a novel regularization technique based on enhancing our dataset with corrupted copies of the original data. The motivation is that since the learning algorithm lacks information about which parts of the data are reliable, it has to produce more robust classification functions. We then demonstrate how this regularization leads to redundancy in the resulting classifiers, which is somewhat in contrast to the common interpretations of the Occam`s razor principle. Using this framework, we propose a simple addition to the gentle boosting algorithm which enables it to work with only a few examples. We test this new algorithm on a variety of datasets and show convincing results.},
 month        = {nov~12},
 number       = {CBCL-242},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-025.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-025.pdf},
}

@techreport{CBCL-243,
 author       = {Serre, Lior Wolf Thomas and Poggio, Tomaso},
 title        = {A new biologically motivated framework for robust object recognition},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In this paper, we introduce a novel set of features for robust object recognition, which exhibits outstanding performances on a variety of object categories while being capable of learning from only a few training examples. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system - motivated by a quantitative model of visual cortex - outperforms state-of-the-art systems on a variety of object image datasets from different groups. We also show that our system is able to learn from very few examples with no prior category knowledge. The success of the approach is also a suggestive plausibility proof for a class of feed-forward models of object recognition in cortex. Finally, we conjecture the existence of a universal overcomplete dictionary of features that could handle the recognition of all object categories.},
 month        = {nov~14},
 number       = {CBCL-243},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-026.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-026.pdf},
}

@techreport{CBCL-244,
 author       = {Balas, Benjamin},
 title        = {Using computational models to study texture representations in the human visual system.},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Traditionally, human texture perception has been studied using artificial textures made of random-dot patterns or abstract structured elements. At the same time, computer algorithms for the synthesis of natural textures have improved dramatically. The current study seeks to unify these two fields of research through a psychophysical assessment of a particular computational model, thus providing a sense of what image statistics are most vital for representing a range of natural textures. We employ Portilla and Simoncelli`s 2000 model of texture synthesis for this task (a parametric model of analysis and synthesis designed to mimic computations carried out by the human visual system). We find an intriguing interaction between texture type (periodic v. structured) and image statistics (autocorrelation function and filter magnitude correlations), suggesting different processing strategies may be employed for these two texture families under pre-attentive viewing.},
 month        = {feb~7},
 number       = {CBCL-244},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-002.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-002.pdf},
}

@techreport{CBCL-245,
 author       = {Kouh, Minjoon and Poggio, Tomaso},
 title        = {A general mechanism for tuning},
 subtitle     = {Gain control circuits and synapses underlie tuning of cortical neurons},
 year         = {2004},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Tuning to an optimal stimulus is a widespread property of neurons in cortex. We propose that such tuning is a consequence of normalization or gain control circuits. We also present a biologically plausible neural circuitry of tuning.},
 month        = {dec~31},
 number       = {CBCL-245},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-031.ps; ftp://publications.ai.mit.edu/ai-publications/2004/AIM-2004-031.pdf},
}

@techreport{CBCL-246,
 author       = {Balas, Pawan Sinha Benjamin},
 title        = {Receptive field structures for recognition},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Localized operators, like Gabor wavelets and difference-of-Gaussian filters, are considered to be useful tools for image representation. This is due to their ability to form a sparse code` that can serve as a basis set for high-fidelity reconstruction of natural images. However, for many visual tasks, the more appropriate criterion of representational efficacy is recognition`, rather than reconstruction`. It is unclear whether simple local features provide the stability necessary to subserve robust recognition of complex objects. In this paper, we search the space of two-lobed differential operators for those that constitute a good representational code under recognition/discrimination criteria. We find that a novel operator, which we call the dissociated dipole` displays useful properties in this regard. We describe simple computational experiments to assess the merits of such dipoles relative to the more traditional local operators. The results suggest that non-local operators constitute a vocabulary that is stable across a range of image transformations.},
 month        = {mar~1},
 number       = {CBCL-246},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-006.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-006.pdf},
}

@techreport{CBCL-247,
 author       = {Bileschi, Lior Wolf Stanley},
 title        = {Combining Variable Selection with Dimensionality Reduction},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper bridges the gap between variable selection methods (e.g., Pearson coefficients, KS test) and dimensionality reduction algorithms (e.g., PCA, LDA). Variable selection algorithms encounter difficulties dealing with highly correlated data, since many features are similar in quality. Dimensionality reduction algorithms tend to combine all variables and cannot select a subset of significant variables. Our approach combines both methodologies by applying variable selection followed by dimensionality reduction. This combination makes sense only when using the same utility function in both stages, which we do. The resulting algorithm benefits from complex features as variable selection algorithms do, and at the same time enjoys the benefits of dimensionality reduction.1},
 month        = {mar~30},
 number       = {CBCL-247},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-009.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-009.pdf},
}

@techreport{CBCL-248,
 author       = {Caponnetto, Andrea and Vito, Ernesto De},
 title        = {Fast Rates for Regularized Least-squares Algorithm},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We develop a theoretical analysis of generalization performances of regularized least-squares on reproducing kernel Hilbert spaces for supervised learning. We show that the concept of effective dimension of an integral operator plays a central role in the definition of a criterion for the choice of the regularization parameter as a function of the number of samples. In fact, a minimax analysis is performed which shows asymptotic optimality of the above-mentioned criterion.},
 month        = {apr~14},
 number       = {CBCL-248},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-013.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-013.pdf},
}

@techreport{CBCL-249,
 author       = {Vito, Ernesto De and Caponnetto, Andrea},
 title        = {Risk Bounds for Regularized Least-squares Algorithm with Operator-valued kernels},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We show that recent results in [3] on risk bounds for regularized least-squares on reproducing kernel Hilbert spaces can be straightforwardly extended to the vector-valued regression setting. We first briefly introduce central concepts on operator-valued kernels. Then we show how risk bounds can be expressed in terms of a generalization of effective dimension.},
 month        = {may~16},
 number       = {CBCL-249},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-015.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-015.pdf},
}

@techreport{CBCL-250,
 author       = {Caponnetto, Andrea and Rakhlin, Alexander},
 title        = {Some Properties of Empirical Risk Minimization over Donsker Classes},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We study properties of algorithms which minimize (or almost minimize) empirical error over a Donsker class of functions. We show that the L2-diameter of the set of almost-minimizers is converging to zero in probability. Therefore, as the number of samples grows, it is becoming unlikely that adding a point (or a number of points) to the training set will result in a large jump (in L2 distance) to a new hypothesis. We also show that under some conditions the expected errors of the almost-minimizers are becoming close with a rate faster than n{\textasciicircum}-1/2.},
 month        = {may~17},
 number       = {CBCL-250},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-018.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-018.pdf},
}

@techreport{CBCL-251,
 author       = {Wu, Jia Jane},
 title        = {Comparing Visual Features for Morphing Based Recognition},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This thesis presents a method of object classification using the idea of deformable shape matching. Three types of visual features, geometric blur, C1 and SIFT, are used to generate feature descriptors. These feature descriptors are then used to find point correspondences between pairs of images. Various morphable models are created by small subsets of these correspondences using thin-plate spline. Given these morphs, a simple algorithm, least median of squares (LMEDS), is used to find the best morph. A scoring metric, using both LMEDS and distance transform, is used to classify test images based on a nearest neighbor algorithm. We perform the experiments on the Caltech 101 dataset [5]. To ease computation, for each test image, a shortlist is created containing 10 of the most likely candidates. We were unable to duplicate the performance of [1] in the shortlist stage because we did not use hand-segmentation to extract objects for our training images. However, our gain from the shortlist to correspondence stage is comparable to theirs. In our experiments, we improved from 21},
 month        = {may~25},
 number       = {CBCL-251},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AITR-2005-002.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AITR-2005-002.pdf},
}

@techreport{CBCL-252,
 author       = {Ernesto De Vito Andrea Caponnetto, Lorenzo Rosasco and Verri, Alessandro},
 title        = {Empirical Effective Dimension and Optimal Rates for Regularized Least Squares Algorithm},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper presents an approach to model selection for regularized least-squares on reproducing kernel Hilbert spaces in the semi-supervised setting. The role of effective dimension was recently shown to be crucial in the definition of a rule for the choice of the regularization parameter, attaining asymptotic optimal performances in a minimax sense. The main goal of the present paper is showing how the effective dimension can be replaced by an empirical counterpart while conserving optimality. The empirical effective dimension can be computed from independent unlabelled samples. This makes the approach particularly appealing in the semi-supervised setting.},
 month        = {may~27},
 number       = {CBCL-252},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-019.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-019.pdf},
}

@techreport{CBCL-253,
 author       = {James J. DiCarlo Chou Hung, Gabriel Kreiman, Tomaso Poggio},
 title        = {Ultra-fast Object Recognition from Few Spikes},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Understanding the complex brain computations leading to object recognition requires quantitatively characterizing the information represented in inferior temporal cortex (IT), the highest stage of the primate visual stream. A read-out technique based on a trainable classifier is used to characterize the neural coding of selectivity and invariance at the population level. The activity of very small populations of independently recorded IT neurons (~100 randomly selected cells) over very short time intervals (as small as 12.5 ms) contains surprisingly accurate and robust information about both object identity` and category`, which is furthermore highly invariant to object position and scale. Significantly, selectivity and invariance are present even for novel objects, indicating that these properties arise from the intrinsic circuitry and do not require object-specific learning. Within the limits of the technique, there is no detectable difference in the latency or temporal resolution of the IT information supporting so-called categorization` (a.k. basic level) and identification` (a.k. subordinate level) tasks. Furthermore, where information, in particular information about stimulus location and scale, can also be read-out from the same small population of IT neurons. These results show how it is possible to decode invariant object information rapidly, accurately and robustly from a small population in IT and provide insights into the nature of the neural code for different kinds of object-related information.},
 month        = {jul~6},
 number       = {CBCL-253},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-022.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-022.pdf},
}

@techreport{CBCL-254,
 author       = {Yokono, Jerry Jun and Poggio, Tomaso},
 title        = {Boosting a Biologically Inspired Local Descriptor for Geometry-free Face and Full Multi-view 3D Object Recognition},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Object recognition systems relying on local descriptors are increasingly used because of their perceived robustness with respect to occlusions and to global geometrical deformations. Descriptors of this type {\textendash} based on a set of oriented Gaussian derivative filters {\textendash} are used in our recognition system. In this paper, we explore a multi-view 3D object recognition system that does not use explicit geometrical information. The basic idea is to find discriminant features to describe an object across different views. A boosting procedure is used to select features out of a large feature pool of local features collected from the positive training examples. We describe experiments on face images with excellent recognition rate.},
 month        = {jul~7},
 number       = {CBCL-254},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-023.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-023.pdf},
}

@techreport{CBCL-255,
 author       = {Das, Sanmay},
 title        = {Learning to Trade with Insider Information},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper introduces algorithms for learning how to trade using insider (superior) information in Kyle's model of financial markets. Prior results in finance theory relied on the insider having perfect knowledge of the structure and parameters of the market. I show here that it is possible to learn the equilibrium trading strategy when its form is known even without knowledge of the parameters governing trading in the model. However, the rate of convergence to equilibrium is slow, and an approximate algorithm that does not converge to the equilibrium strategy achieves better utility when the horizon is limited. I analyze this approximate algorithm from the perspective of reinforcement learning and discuss the importance of domain knowledge in designing a successful learning algorithm.},
 month        = {oct~7},
 number       = {CBCL-255},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-028.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-028.pdf},
}

@techreport{CBCL-256,
 author       = {Amara, Gadi Geiger Domenic G},
 title        = {Towards the Prevention of Dyslexia},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Previous studies have shown that dyslexic individuals who supplement windowed reading practice with intensive small-scale hand-eye coordination tasks exhibit marked improvement in their reading skills. Here we examine whether similar hand-eye coordination activities, in the form of artwork performed by children in kindergarten, first and second grades, could reduce the number of students at-risk for reading problems. Our results suggest that daily hand-eye coordination activities significantly reduce the number of students at-risk. We believe that the effectiveness of these activities derives from their ability to prepare the students perceptually for reading.},
 month        = {oct~18},
 number       = {CBCL-256},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-029.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-029.pdf},
}

@techreport{CBCL-257,
 author       = {Lippert, Ross and Rifkin, Ryan},
 title        = {Asymptotics of Gaussian Regularized Least-Squares},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We consider regularized least-squares (RLS) with a Gaussian kernel. We prove that if we let the Gaussian bandwidth $\sigma  i\rghtarrow {\i}nfty$ while letting the regularization parameter ${\l}ambda \g\rhtarrow 0$, the RLS solution tends to a polynomial whose order is controlled by the relative rates of decay of $\frac1\sigma ^2$ and ${\l}ambda$: if ${\l}ambda = \sigma ^-(2k+1)$, then, as $\sigma  \rh\rtarrow {\i}nfty$, the RLS solution tends to the $k$th order polynomial with minimal empirical error. We illustrate the result with an example.},
 month        = {oct~20},
 number       = {CBCL-257},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-030.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-030.pdf},
}

@techreport{CBCL-258,
 author       = {Ivanov, Thomas Serre Yuri and Bouvrie, Jacob},
 title        = {Confidence weighted classifier combination for multi-modal human identification},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {In this paper we describe a technique of classifier combination used in a human identification system. The system integrates all available features from multi-modal sources within a Bayesian framework. The framework allows representing a class of popular classifier combination rules and methods within a single formalism. It relies on a ''per-class'' measure of confidence derived from performance of each classifier on training data that is shown to improve performance on a synthetic data set. The method is especially relevant in autonomous surveillance setting where varying time scales and missing features are a common occurrence. We show an application of this technique to the real-world surveillance database of video and audio recordings of people collected over several weeks in the office setting.},
 month        = {dec~14},
 number       = {CBCL-258},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-035.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-035.pdf},
}

@techreport{CBCL-259,
 author       = {T. Poggio T. Serre, M. Kouh, C. Cadieu U. Knoblich G. Kreiman},
 title        = {A theory of object recognition},
 subtitle     = {Computations and circuits in the feedforward path of the ventral stream in primate visual cortex},
 year         = {2005},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We describe a quantitative theory to account for the computations performed by the feedforward path of the ventral stream of visual cortex and the local circuits implementing them. We show that a model instantiating the theory is capable of performing recognition on datasets of complex images at the level of human observers in rapid categorization tasks. We also show that the theory is consistent with (and in some case has predicted) several properties of neurons in V1, V4, IT and PFC. The theory seems sufficiently comprehensive, detailed and satisfactory to represent an interesting challenge for physiologists and modelers: either disprove its basic features or propose alternative theories of equivalent scope. The theory suggests a number of open questions for visual physiology and psychophysics.},
 month        = {dec~19},
 number       = {CBCL-259},
 url          = {ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-036.ps; ftp://publications.ai.mit.edu/ai-publications/2005/AIM-2005-036.pdf},
}

@techreport{CBCL-75,
 author       = {Girosi, Michael Jones Federico and Poggio, Tomaso},
 title        = {Priors Stabilizers and Basis Functions},
 subtitle     = {From Regularization to Radial, Tensor and Additive Splines},
 year         = {1993},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We had previously shown that regularization principles lead to approximation schemes, as Radial Basis Functions, which are equivalent to networks with one layer of hidden units, called Regularization Networks. In this paper we show that regularization networks encompass a much broader range of approximation schemes, including many of the popular general additive models, Breiman's hinge functions and some forms of Projection Pursuit Regression. In the probabilistic interpretation of regularization, the different classes of basis functions correspond to different classes of prior probabilities on the approximating function spaces, and therefore to different types of smoothness assumptions. In the final part of the paper, we also show a relation between activation functions of the Gaussian and sigmoidal type.},
 month        = {jun~6},
 number       = {CBCL-75},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1430.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1430.pdf},
}

@techreport{CBCL-76,
 author       = {Vetter, Tomaso Poggio Thomas and B'ulthoff, Heinrich},
 title        = {3D Object Recognition},
 subtitle     = {Symmetry and Virtual Views},
 year         = {1992},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Many 3D objects in the world around us are strongly constrained. For instance, not only cultural artifacts but also many natural objects are bilaterally symmetric. Thoretical arguments suggest and psychophysical experiments confirm that humans may be better in the recognition of symmetric objects. The hypothesis of symmetry-induced virtual views together with a network model that successfully accounts for human recognition of generic 3D objects leads to predictions that we have verified with psychophysical experiments.},
 month        = {dec~6},
 number       = {CBCL-76},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1409.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1409.pdf},
}

@techreport{CBCL-77,
 author       = {Poggio, Tomaso and Hurlbert, Anya},
 title        = {Observations on Cortical Mechanisms for Object Recognition andsLearning},
 year         = {1993},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {This paper sketches a hypothetical cortical architecture for visual 3D object recognition based on a recent computational model. The view-centered scheme relies on modules for learning from examples, such as Hyperbf-like networks. Such models capture a class of explanations we call Memory-Based Models (MBM) that contains sparse population coding, memory-based recognition, and codebooks of prototypes. Unlike the sigmoidal units of some artificial neural networks, the units of MBMs are consistent with the description of cortical neurons. We describe how an example of MBM may be realized in terms of cortical circuitry and biophysical mechanisms, consistent with psychophysical and physiological data.},
 month        = {dec~6},
 number       = {CBCL-77},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1404.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1404.pdf},
}

@techreport{CBCL-78,
 author       = {Shashua, Amnon},
 title        = {Geometric and Algebraic Aspects of 3D Affine and Projective Structures from Perspective 2D Views},
 year         = {1993},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We investigate the differences {\textemdash} conceptually and algorithmically {\textemdash} between affine and projective frameworks for the tasks of visual recognition and reconstruction from perspective views. It is shown that an affine invariant exists between any view and a fixed view chosen as a reference view. This implies that for tasks for which a reference view can be chosen, such as in alignment schemes for visual recognition, projective invariants are not really necessary. We then use the affine invariant to derive new algebraic connections between perspective views. It is shown that three perspective views of an object are connected by certain algebraic functions of image coordinates alone (no structure or camera geometry needs to be involved).},
 month        = {jul~6},
 number       = {CBCL-78},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1405.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1405.pdf},
}

@techreport{CBCL-80,
 author       = {Beymer, Amnon Shashua David and Poggio, Tomaso},
 title        = {Example Based Image Analysis and Synthesis},
 year         = {1993},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Image analysis and graphics synthesis can be achieved with learning techniques using directly image examples without physically- based, 3D models. In our technique: {\textendash} the mapping from novel images to a vector of ''pose'' and ''expression'' parameters can be learned from a small set of example images using a function approximation technique that we call an analysis network; {\textendash} the inverse mapping from input ''pose'' and ''expression'' parameters to output images can be synthesized from a small set of example images and used to produce new images using a similar synthesis network. The techniques described here have several applications in computer graphics, special effects, interactive multimedia and very low bandwidth teleconferencing.},
 month        = {nov~6},
 number       = {CBCL-80},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1431.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1431.pdf},
}

@techreport{CBCL-81,
 author       = {Schyns, Philippe G. and Bulthoff, Heinrich H.},
 title        = {Conditions for Viewpoint Dependent Face Recognition},
 year         = {1993},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Poggio and Vetter (1992) showed that learning one view of a bilaterally symmetric object could be sufficient for its recognition, if this view allows the computation of a symmetric, ''virtual,'' view. Faces are roughly bilaterally symmetric objects. Learning a side- view{\textendash}which always has a symmetric view{\textendash} should allow for better generalization performances than learning the frontal view. Two psychophysical experiments tested these predictions. Stimuli were views of shaded 3D models of laser-scanned faces. The first experiment tested whether a particular view of a face was canonical. The second experiment tested which single views of a face give rise to best generalization performances. The results were compatible with the symmetry hypothesis: Learning a side view allowed better generalization performances than learning the frontal view.},
 month        = {aug~6},
 number       = {CBCL-81},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1432.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1432.pdf},
}

@techreport{CBCL-82,
 author       = {Shadmehr, Reza and Mussa-Ivaldi, Ferdinando},
 title        = {Geometric Structure of the Adaptive Controller of the Human Arm},
 year         = {1993},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The objects with which the hand interacts with may significantly change the dynamics of the arm. How does the brain adapt control of arm movements to this new dynamic? We show that adaptation is via composition of a model of the task's dynamics. By exploring generalization capabilities of this adaptation we infer some of the properties of the computational elements with which the brain formed this model: the elements have broad receptive fields and encode the learned dynamics as a map structured in an intrinsic coordinate system closely related to the geometry of the skeletomusculature. The low- -level nature of these elements suggests that they may represent asset of primitives with which a movement is represented in the CNS.},
 month        = {jul~6},
 number       = {CBCL-82},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1437.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1437.pdf},
}

@techreport{CBCL-83,
 author       = {Jordan, Michael I. and Jacobs, Robert A.},
 title        = {Hierarchical Mixtures of Experts and the EM Algorithm},
 year         = {1993},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present a tree-structured architecture for supervised learning. The statistical model underlying the architecture is a hierarchical mixture model in which both the mixture coefficients and the mixture components are generalized linear models (GLIM's). Learning is treated as a maximum likelihood problem; in particular, we present an Expectation- Maximization (EM) algorithm for adjusting the parameters of the architecture. We also develop an on-line learning algorithm in which the parameters are updated incrementally. Comparative simulation results are presented in the robot dynamics domain.},
 month        = {aug~23},
 number       = {CBCL-83},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1440.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1440.pdf},
}

@techreport{CBCL-84,
 author       = {Jaakkola, Michael I. Jordan Tommi and Singh, Satinder P.},
 title        = {On the Convergence of Stochastic Iterative Dynamic Programming Algorithms},
 year         = {1993},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {Recent developments in the area of reinforcement learning have yielded a number of new algorithms for the prediction and control of Markovian environments. These algorithms, including the TD(lambda) algorithm of Sutton (1988) and the Q-learning algorithm of Watkins (1989), can be motivated heuristically as approximations to dynamic programming (DP). In this paper we provide a rigorous proof of convergence of these DP- based learning algorithms by relating them to the powerful techniques of stochastic approximation theory via a new convergence theorem. The theorem establishes a general class of convergent algorithms to which both TD(lambda) and Q-learning belong.},
 month        = {aug~23},
 number       = {CBCL-84},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1441.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1441.pdf},
}

@techreport{CBCL-85,
 author       = {Shashua, Amnon and Toelg, Sebastian},
 title        = {The Quadric Reference Surface},
 subtitle     = {Theory and Applications},
 year         = {1994},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The conceptual component of this work is about ''reference surfaces'' which are the dual of reference frames often used for shape representation purposes. The theoretical component of this work involves the question of whether one can find a unique (and simple) mapping that aligns two arbitrary perspective views of an opaque textured quadric surface in 3D, given (i) few corresponding points in the two views, or (ii) the outline conic of the surface in one view (only) and few corresponding points in the two views. The practical component of this work is concerned with applying the theoretical results as tools for the task of achieving full correspondence between views of arbitrary objects.},
 month        = {jun~23},
 number       = {CBCL-85},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1448.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1448.pdf},
}

@techreport{CBCL-91,
 author       = {Marroquin, Jose L.},
 title        = {Measure Fields for Function Approximation},
 year         = {1993},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {The computation of a piecewise smooth function that approximates a finite set of data points may be decomposed into two decoupled tasks: first, the computation of the locally smooth models, and hence, the segmentation of the data into classes that consist on the sets of points best approximated by each model, and second, the computation of the normalized discriminant functions for each induced class. The approximating function may then be computed as the optimal estimator with respect to this measure field. We give an efficient procedure for effecting both computations, and for the determination of the optimal number of components.},
 month        = {jun~6},
 number       = {CBCL-91},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1433.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1433.pdf},
}

@techreport{CBCL-96,
 author       = {Buelthoff, Shimon Y. Edelman Heinrich H. and Tarr, Michael J.},
 title        = {How are Three-Deminsional Objects Represented in the Brain?},
 year         = {1994},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We discuss a variety of object recognition experiments in which human subjects were presented with realistically rendered images of computer-generated three-dimensional objects, with tight control over stimulus shape, surface properties, illumination, and viewpoint, as well as subjects' prior exposure to the stimulus objects. In all experiments recognition performance was: (1) consistently viewpoint dependent; (2) only partially aided by binocular stereo and other depth information, (3) specific to viewpoints that were familiar; (4) systematically disrupted by rotation in depth more than by deforming the two-dimensional images of the stimuli. These results are consistent with recently advanced computational theories of recognition based on view interpolation.},
 month        = {apr~2},
 number       = {CBCL-96},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1000-1499/AIM-1479.ps.Z; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1479.pdf},
}

@techreport{AIM-573A_a543c91ccd0f11ee95f5f0d4152957ac,
 author       = {Richter, J. and Ullman, S.},
 title        = {A Model for the Spatio-Temporal Organization of X- and Y-Type Ganglion Cells in the Primate Retina},
 year         = {1980},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {A model is proposed for the spatial and temporal characteristics of X- and Y-type responses of ganglion cells in the primate retina. The model is related to a theory of directional selectivity proposed by Marr     Ullman (1981). The X- and Y-type responses predicted by the model to a variety of stimuli are examined and compared with electrophysiological recordings. A number of implications and predictions are discussed.},
 month        = {apr~6},
 number       = {AIM-573A},
 url          = {ftp://publications.ai.mit.edu/ai-publications/500-999/AIM-573a.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-573a.pdf},
}

@techreport{CBCL-129_a543d088cd0f11ee95f5f0d4152957ac,
 author       = {de Marcken, Carl},
 title        = {The Unsupervised Acquisition of a Lexicon from Continuous Speech},
 year         = {1996},
 institution  = {MIT Artificial Intelligence Laboratory},
 tags         = {__untagged},
 abstract     = {We present an unsupervised learning algorithm that acquires a natural-language lexicon from raw speech. The algorithm is based on the optimal encoding of symbol sequences in an MDL framework, and uses a hierarchical representation of language that overcomes many of the problems that have stymied previous grammar-induction procedures. The forward mapping from symbol sequences to the speech stream is modeled using features based on articulatory gestures. We present results on the acquisition of lexicons and language models from raw speech, text, and phonetic transcripts, and demonstrate that our algorithm compares very favorably to other reported results with respect to segmentation performance and statistical efficiency.},
 month        = {jan~18},
 number       = {CBCL-129},
 url          = {ftp://publications.ai.mit.edu/ai-publications/1500-1999/AIM-1558.ps; ftp://publications.ai.mit.edu/ai-publications/pdf/AIM-1558.pdf},
}
