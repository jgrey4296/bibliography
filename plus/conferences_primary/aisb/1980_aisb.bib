
@Proceedings{80:_proceed_aisb_confer_artif_intel_,
 title        = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 url2         = {https://aisb.org.uk/wp-content/uploads/2019/12/aisb1980.pdf},
 file         = {/media/john/data/todo/pdfs/proceedings/aisb/aisb1980.pdf},
 editor       = {Steven Hardy},
 year         = {1980},
 url          = {https://dl.acm.org/doi/proceedings/10.5555/3069422},
}

@inproceedings{10.5555/3069422.3069423,
 author       = {Adam, Anne and Laurent, Jean-Pierre},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Automatic Diagnostics of Semantic Errors},
 year         = {1980},
 abstract     = {We present in this paper an original approach of Debugging. The general goal in Automatic Verification of Programs is to prove that a program is correct or incorrect. This does not generally provide enough information to catch the bugs. On the opposite, the purpose of the debugging system LAURA, that we have designed and implemented, is to find the errors.In order to debug a student program, the LAURA system uses a procedural description of the program task, under the form of a program model. Debugging is then viewed as a comparison of two graphs, built from the student program and from the program model. The system can apply powerful semantic transformations on the graphs to increase their resemblances and to identify subgraphs that perform a same task.The LAURA system has shown to be able to determine the correctness of programs implemented in various ways, very different from the program model. It can also express sophisticated diagnostics and set up proper corrections.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {7-16},
 keywords     = {diagnostics of errors, program transformations, debugging, graphs of program},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069424,
 author       = {Bibel, Wolfgang},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {A Comparative Study of Several Proof Procedures},
 year         = {1980},
 abstract     = {In this paper three algorithms for testing the complementarity of a matrix (representing a propositional formula) are developed in stages. Any of these algorithms is distinguished from its predecessor by a specific feature (linearity, jump, non-normal form) which endows it with a provable advantage w.r.t. its performance. For well-known proof procedures it is shown that they can be simulated by at least one of these algorithms.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {17-24},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069425,
 author       = {Bobrow, Daniel G. and Goldstein, Ira P.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Representing Design Alternatives},
 year         = {1980},
 abstract     = {Artificial intelligence systems are complex designed artifacts. Techniques used in Al systems to describe structures and to represent alternatives can be used to support the design of the systems themselves. PIE is an experimental personal information environment which provides users with descriptive structures for programs and documents. In PIE, alternative designs for programs and documents are simultaneously viewable in the system through the use of a context structured database. This short paper gives an overview of how the use of these facilities improves the design environment for builders of software systems.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {25-35},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069426,
 author       = {Bramer, M. A.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Pattern-Based Representations of Knowledge in the Game of Chess},
 year         = {1980},
 abstract     = {The focus of recent Artificial Intelligence research into Computer Chess has been on endgames. These afford the possibility of controlled experimentation, whilst retaining much of the complexity of the full game of chess. This paper discusses some of the specific reasons for complexity in the endgame and considers its effects on human chess-playing strategy, textbook descriptions and the development of programs. In programming the endgame the researcher is faced with a range of decisions concerning the quality of play to be aimed at, the balance between knowledge and search to be adopted and the degree to which the playing strategy should be understandable to human chessplayers. A model for representing pattern-knowledge is described which has enabled the development of algorithms to play a number of endgames. Three algorithms representing different levels of performance for the endgame King and Pawn against King are compared, in order to discuss the tradeoff between complexity and completeness, on the one hand, and compactness and comprehensibility, on the other. Finally, the role of search in reducing the amount of knowledge to be memorised is considered and an extension to the basic model to incorporate deeper search is discussed.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {36-45},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069427,
 author       = {Byrd, Lawrence and Borning, Alan},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Extending Mecho to Solve Statics Problems},
 year         = {1980},
 abstract     = {Mecho is a computer program for solving mechanics problems. To test the generality and extensibility of its representation and search control mechanisms, we extended Mecho to handle problems from a new domain, namely that of statics problems. This paper describes the representation and solution of some of these problems.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {46-51},
 keywords     = {statics, inference, problem solving, mechanics},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069428,
 author       = {Cappelli, A. and Ferrari, C. and Moretti, L. and Prodanof, I. and Stock, O.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Automatic Analysis of Italian},
 year         = {1980},
 abstract     = {ATNSYS, an automatic syntactic analyser, has been used for a number of experiments with Italian texts. It is provided with a heuristic mechanism based on probability evaluation. A 'verb frame' representation is introduced. Roth these aspects are discussed and the results of our experiments are considered.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {52-57},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069429,
 author       = {Cater, A. W.S.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Analysing English Text: A Nondeterministic Approach with Limited Memory},
 year         = {1980},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {58-71},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069430,
 author       = {Cerri, Stefano and Breuker, Joost},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {A Rather Intelligent Language Teacher},
 year         = {1980},
 abstract     = {A semi-intelligent CAI program for teaching the use of conjunctions in a number of foreign languages is presented. The representation of well known confusions in the use of these conjunctions form the basis of tutorial strategies to correct the student. The program is written as a try-out of DART, an ATN-based system for authoring intelligent CAI lessons on the PLATO-system.Emphasis is put on the fact that intelligence in CAI is not all-or-none: the degree of intelligence required is dependent on the variances permitted and expected in the student's responses. Misconceptions are one of the major sources of variance. DART is proposed as facilitating the transition between traditional and intelligent CAI.},
crossref      = {80:_proceed_aisb_confer_artif_intel_},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {72-76},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069431,
 author       = {Clocksin, W. F.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {The Effect of Motion Contrast on Surface Slant and Edge Detection},
 year         = {1980},
 abstract     = {He present here three results obtained from our investigations of a computational model of the effect of motion contrast on the perception of physical (3D) surfaces. The first result is a set of equations that describes the relationship between fixed bounded surfaces and the motion contrast information given to a moving observer. It is shown how to extract surface slant and the types of bounding edges. The second result is a computer program that implements the theory. The third result is a set of graphs, derived from the equations, that depicts the psychophysical thresholds for slant and edge detection under a variety of conditions for human subjects and for computer programs. The graphs show the precise conditions under which slants and edges can be extracted from motion contrast information.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {77-85},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069432,
 author       = {Draper, Stephen W.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Using Models to Augment Rule-Based Programs},
 year         = {1980},
 abstract     = {This paper discusses the design of a program that tackles the ambiguity resulting from the interpretation of line-drawings by means of geometric constraints alone. It does this by supplementing its basic geometric reasoning by means of a set of models of various sizes. Earlier programs are analysed in terms of models, and three different functions for models are distinguished. Finally, principles for selecting models for the present purpose are related to the concept of a "mapping event" between the picture and scene-domains.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {86-91},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069433,
 author       = {Eigemeier, H. and Knabe, Ch. and Raulefs, P. and Tramer, K.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Automatic Implementation of Algebraic Specifications of Abstract Data Types},
 year         = {1980},
 abstract     = {The system ADTCOMP which constructs LISP-implementations from algebraic specifications of abstract data types is presented. ADTCOMP accepts specifications with conditional axioms and hidden operations (parameterized specifications are not yet accepted). Code is generated by applying programming knowledge codified in terms of production rules.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {92-102},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069434,
 author       = {Eisenstadt, Marc and Laubsch, Joachim},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Towards an Automated Debugging Assistant for Novice Programmers},
 year         = {1980},
 abstract     = {This paper describes the design philosophy underlying a debugging assistant which will help novice programmers debug arbitrary programs of their own design. The assistant synthesizes plans which are suitable for carrying out a particular set of intentions. The intentions may either be specified in advance (by us), or obtained from the student at debugging-time. The plans are represented in an abstract plan-language, and are compared against a similar representation of the student's own code in an attempt to find anomalies. The system focusses mainly on teleological bugs (unachieved intentions), but can also help to pinpoint the source of more complex conceptual bugs, even though it cannot recommended specific patches.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {103-113},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069435,
 author       = {Eisinger, N. and Siekmann, J. and Smolka, G. and Unvericht, E. and Walther, Chr.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {The Markgraf Karl Refutation Procedure},
 year         = {1980},
 abstract     = {The current state of a Theorem Proving System (The Markgraf Karl Refutation Procedure) at the University of Karlsruhe is presented. The goal of this project can be summarized by the following three claims: it is possible to program a theorem prover (TP) and augment it by appropriate heuristics and domain-specific knowledge such that(i) it will display an 'active' and directed behaviour in its striving for a proof, rather than the 'passive' combinatorial search through very large search spaces, which was the characteristic behaviour of the TPs of the past. Consequently(ii) it will not generate a search space of many thousands of irrelevant clauses, but will find a proof with comparatively few redundant derivation steps.(iii) Such a TP will establish an unprecedented leap in performance over previous TPs expressed in terms of the difficulty of the theorems it can prove.The results obtained thus far corroborate the first two claims.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {114-126},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069436,
 author       = {Fidler, Eduard J.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Decision Rules Foe Binary Choices: A Process Tracing Study},
 year         = {1980},
 abstract     = {This paper proposes a descriptive choice model for decisions involving two alternatives and gives experimental results for twenty-eight decision makers. For each decision maker a computer simulation model, based on verbal accounts of subjects' thought processes, was developed. An analysis of these models indicates substantial support for the proposed model. Additionally, the computer models were found to predict correctly more than 99\% of all reliable decisions. An analysis of the incorrect predictions indicates that both the selection of decision rules, as well as their parameters are partly governed by a probabilistic process.During the past several years, the understanding of the thought process underlying decision making behavior has received more and more attention in the literature. Instead of only focusing on an analysis of the relationships between decision attributes and choice outcomes by means of regression analysis [cf. Slovic and Lichtenstein, 1971 for an extensive review of that literature], students of choice behavior are increasingly investigating predecisional behavior, like the acquisition, evaluation, and integration of information [e.g., Svenson, 1979]. Unfortunately, relatively little research is available that has examined in detail the cognitive processes of decision makers. Furthermore, few attempts have been made to integrate empirical findings into a theoretical framework. Hence, the major goal of this study is to examine in detail the choice strategies of decision makers, and to develop a theoretical model for binary choices. More specifically, the plan of this study is to provide first a short summary of recent work on decision-making processes. Then, a binary choice model is presented and the results of two experiments are described and discussed in the light of the findings of other work on choice behavior.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {127-135},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069437,
 author       = {Greussay, Patrick},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Program Understanding by Reduction Sets},
 year         = {1980},
 abstract     = {While building or understanding large LISP systems, many small auxiliary functions are often subject to errors or misunderstanding, In the case of very Involved recursions. RAINBOW is a specialized program understanding system able to reduce automatically such sets of recursive functions to a form where the goal of these sets are clearly displayed. RAINBOW can display Interactively the goal-forms Into two sets of new external 2-dlmenslonal notations: recursive and linear. Program understanding is obtained by the translation of the original set of LISP functions Into the open recursive notation, then by elementary symbolic evaluation yielding closed linear forms of the original functions. Those linear forms are exactly the goals wanted. RAINBOW operates efficiently on a definite class of LISP functions, and uses an extendable set of reduction rules, which constitute the symbolic interpreter. RAINBOW can be used interactively if a user want to verify that a set of functions perform its intended goal, or can be incorporated easily as a specialized component of a larger program understanding system. This paper shows how RAINBOW operates on sets of recursive functions building combinatorial objects.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {136-142},
 keywords     = {VLISP, symbolic interpretation, program debugging, program transformation, automatic program understanding, RAINBOW system, multiple representations},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069438,
 author       = {Hagert, G\"{o}ran},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Stability and Change of Strategies: Three Simulations of One Subject with One-Year Intervals},
 year         = {1980},
 abstract     = {The stability or change of problem solving strategies, without or with practice, is considered as an important aspect of human problem solving. It is proposed that a strategy is not situation dependent, but reflects stability in the problem solving skill of a subject. It is assumed that without practice in a task a strategy should recur in repeated solutions where the intervals between solutions are long. This hypothesis is investigated in this study. A production system, simulating in detail the behavior of one subject's solution to a spatial series task, is presented. The program is based on a think-aloud protocol produced by the subject while solving the task. The behavior of the program is compared to the subject's solution of the task one and two years later. These comparisons show that the subject uses mainly the same strategy or set of rules on the three occasions, even though the particular solutions on each occasion were rather different in terms of time to solution and answers given. Processing errors and rule modification are two factors that can explain the differences in behavior, rather than switches in the strategies the subject used. The study gives support to the hypothesis about stability of strategies.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {143-147},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069439,
 author       = {Hoenkamp, Edward},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Spontaneous Speech as a Feedback Process},
 year         = {1980},
 abstract     = {This paper explores some minimum requirements for a sentence generating program that claims psychological plausibility, in that it can exhibit the dysfluencies that characterize the spontaneous speaker. A monitor is used to compare what the speaker says, with what he intends to say. To this end a feedback loop is introduced which contains a parser. The research reported here is based on empirical evidence in the literature. The implementation is an effort to use the AI paradigm for theory building in psychology.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {148-152},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069440,
 author       = {Kahn, Kenneth M.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {How to Program a Society},
 year         = {1980},
 abstract     = {Conventional programming languages are inadequate for constructing reasoning systems organized as communities of autonomous individuals. They lack a means of conveniently describing the behavior of individuals, the relationships and communication conventions between individuals and subsocieties.This paper presents the thesis that "actor" languages are ideal as an underlying base in the implementation of societies. The language "Director" is presented as an example of how one can implement individual reasoning agents as actors and their interaction as "message passing". Communication and control conventions are established between the actors to form composite actors that correspond to subsocieties. An example of a large actor system called "Ani" which was implemented in this manner is presented. Portions of Ani's reasoning in creating an animated film are used as illustrations of an actor-based societal reasoning style.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {153-162},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069441,
 author       = {Kodratoff, Yves and Papon, Eric},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {A System for for Program Synthesis and Program Optimization},
 year         = {1980},
 abstract     = {This paper presents an implemented system for the synthesis of tail recursive programs from input-output examples. The system can be also used to perform some new recursive to iterative transforms.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {163-172},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069442,
 author       = {Luger, George F.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Means-Ends Analysis and the Solution of Mechanics Problems},
 year         = {1980},
 abstract     = {Several years ago David Marples (1976) proposed an algorithm for derivation of simultaneous equations in the solution of Mechanics problems. Although the original intent of this algorithm was to assist his undergraduate students at Cambridge in solving applied mathematics problems, it has also proven itself a powerful tool in the MECHO automatic problem solving system (Bundy et al, 1978, 1979). This paper will briefly discuss the Marples' algorithm and demonstrate its use with two mechanics problems. Parts of traces of four humans solving the same problems will be given. Adjustments in the MECHO program are made to show how close the Marples' algorithm can fit the data of the human subjects. Brief concluding comments are made on modelling human behavior with a rule-based language.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {173-183},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069443,
 author       = {Mayhew, John E.H. and Frisby, John P.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Computational and Psychophysical Studies towards a Theory of Human Stereopsis},
 year         = {1980},
 abstract     = {Psychophysical studies are described which pose a strong challenge to models of human stereopsis based on the processing of disparity information within independent spatial frequency tuned binocular channels. These studies support instead the proposal that the processes of human binocular combination integrally relate the extraction of disparity information with the construction of raw primal sketch assertions. This proposal implies binocular combination rules using principles of figural continuity and cross-channel correspondences to disambiguate at a global level matches found independently within spatial frequency channels at a local level. Computer implementations of stereo algorithms based on these rules are described and found to be successful in dealing with a variety of different stereo inputs. The constraints presented by objects which are exploited by these algorithms are discussed. The paper is an abbreviated version of a paper to appear in a special issue of Artificial Intelligence devoted to vision (Mayhew and Frisby, 1980c).},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {184-202},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069444,
 author       = {Mellish, C. S.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Some Problems in Early Noun Phrase Interpretation},
 year         = {1980},
 abstract     = {How does a piece of text provide the information necessary for generating a symbolic "meaning" and how can a computer program be organised to pick up that information? The work described here aims to investigate some of the constraints on the timing of semantic interpretation. In particular, we are interested in seeing to what extent the meaning can be built up in an incremental way as the analysis proceeds from left to right. We look at some problems of noun phrase interpretation in such a scheme and indicate some representational ideas that help to overcome them. This paper is a brief summary of a forthcoming PhD thesis [Hellish 80].},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {203-207},
 keywords     = {reference evaluation, quantification in natural language, parsing, computational linguistics},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069445,
 author       = {Milne, Rob},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Using Determinism to Predict Garden Paths},
 year         = {1980},
 abstract     = {I am interested in making a psychologically valid model of human natural language understanding, and especially in a processing model for predicting when a sentence will be a garden path. While extending the Marcus deterministic parser to include noun-noun modification, several counter examples to Marcus' garden path prediction were found. In this paper I propose that when people encounter an ambigous situation that may lead to a garden path, they use semantics to decide rather than look ahead. I will present an extension to the garden path prediction mechanism of Marcus' parser to account for this and several experiments to test this theory.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {208-213},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069446,
 author       = {Ohlsson, Stellan},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Strategy Grammars an Approach to Generality in Computer Simulation of Human Reasoning},
 year         = {1980},
 abstract     = {The concept of a strategy grammar is introduced as one of several possible approaches to the problem of how to express properties which recur over many simulation programs induced from think-aloud protocols. An example of such a grammar is presented which is capable of generating several specific simulation programs which have been verified against human data. It turns out that additional programs, not corresponding to any observed subject, can be derived from the grammar. If the grammar is interpreted as a theory, such derivations correspond to predictions about which strategies people will be found to use in a particular task domain. Also, it is shown that not all programs found in human data can be derived from the particular grammar shown. Thus, a strategy grammar can categorize subjects with respect to their problem solving strategies. Other approaches to the same problem are briefly commented upon.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {214-222},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069447,
 author       = {Owen, David},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Intermediate Descriptions in "POPEYE"},
 year         = {1980},
 abstract     = {Some ideas are presented, derived from work on the POPEYE vision project, concerning the nature and use of different kinds of intermediate picture descriptions. It is suggested that there are "natural elements" in terms of which stored models should be defined and that it is of prime importance to search for those intermediate picture descriptions which are most characteristic of the expression of such elements.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {223-228},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069448,
 author       = {Ramsay, Allan},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Understanding English Descriptions of Programs},
 year         = {1980},
 abstract     = {A considerable amount of work has been done on verifying that computer programs fit their specifications. However, providing formal specifications is itself a difficult and tedious task, so that programs are generally only documented incompletely and imprecisely. This paper presents a computer system which accepts English descriptions of procedures and relates them to LISP programs that are supposed to implement them. This system is intended to illustrate how "informal" techniques may be used to provide a rough analysis of a program for which incomplete specifications are provided.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {229-233},
 keywords     = {natural language programming, symbolic evaluation, automatic program verification},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069449,
 author       = {Ramsay, Allan},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Parsing English Text},
 year         = {1980},
 abstract     = {This paper presents a technique for parsing English text according to a grammar specified as a set of rewrite rules. The paper describes a compact way of representing such a grammar and presents a program which uses this representation to parse text without backtracking and without repeating work that it has already done.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {234-238},
 keywords     = {control structures, deterministic parsing},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069450,
 author       = {Schefe, Peter},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {The Fuzzy Set Fallacy},
 year         = {1980},
 abstract     = {"Fuzzy set theory" and "fuzzy logic" have been proposed to be useful for applications in pattern recognition and artificial intelligence. It is argued that the concept of a "fuzzy set" is due to an intuitive fallacy induced by a threshold probability distribution. A sketch of an alternative model for dealing with applications considered to be "fuzzy" ones so far is presented. The problem of handwritten character recognition is used as an example.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {239-243},
 keywords     = {recognition of handwritten characters, reasoning with vague concepts, knowledge representation, concept 1earning},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069451,
 author       = {Sloman, Aaron and Owen, David},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Why Visual Systems Process Sketches},
 year         = {1980},
 abstract     = {Why do people interpret sketches, cartoons, etc. so easily? A theory is outlined which accounts for the relation between ordinary visual perception and picture interpretation. Animals and versatile robots need fast, generally reliable and "gracefully degrading" visual systems. This can be achieved by a highly-parallel organisation, in which different domains of structure are processed concurrently, and decisions made on the basis of incomplete analysis. Attendant risks are diminished in a "cognitively friendly world" (CFW). Since high levels of such a system process inherently impoverished and abstract representations, it is ideally suited to the interpretation of pictures.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {244-253},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069452,
 author       = {Sridharan, N. S. and Schmidt, C. F. and Goodson, J. L.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {The Role of World Knowledge in Planning},
 year         = {1980},
 abstract     = {Common-sense planning demands a rich variety of world Knowledge. We have examined here the view that world knowledge can be structured to form the interface between a hierarchy of action types and a hierarchy of types of objects. World knowledge forming this interface includes not only the traditional statements about preconditions and outcomes of actions, but also the normal states of objects participating in the actions and normative actions associated with the objects. Common-sense plans are decomposed into goal-directed, preparation, and the normative components. This has heuristic value and may serve to simplify the planning algorithm. The algorithm invokes world knowledge for goal customization, action specification, computation of preconditions and outcomes, object selection, and for setting up subgoals.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {254-264},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069453,
 author       = {Steedman, M. J. and Ades, A. E.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {An Algorithmic Account of English Main Clause Constructions},
 year         = {1980},
 abstract     = {"The fundamental aim in the linguistic analysis of a language L is to separate the grammatical sequences which are the sentences of L from the ungrammatical sequences which are not sentences of L and to study the structure of the grammatical sequences. The grammar of L will thus be a device that generates all of the grammatical sequences of L and none of the ungrammatical ones." (Chomsky, 1957)},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {265-274},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069454,
 author       = {Steels, Luc},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Description Types in the XPRT-System},
 year         = {1980},
 abstract     = {The XPRT-system has been designed as a basis for implementing knowledge-based expert systems. This paper introduces the description types that are currently available for communicating with this system.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {275-283},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069455,
 author       = {Sussman, Gerald Jay and Holloway, Jack and Knight, Thomas F.},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Computer Aided Evolutionary Design for Digital Integrated Systems},
 year         = {1980},
 abstract     = {We propose to develop a computer aided design tool which can help an engineer deal with system evolution from the initial phases of design right through the testing and maintenance phases. We imagine a design system which can function as a junior assistant. It provides a total conversational and graphical environment. It remembers the reasons for design choices and can retrieve and do simple deductions with them. Such a system can provide a designer with information relevant to a proposed modification and can help him understand the consequences of simple modifications by pointing out the structures and functions which will be affected by the modifications. The designer's assistant will maintain a vast amount of such annotation on the structure and function of the system being evolved and will be able to retrieve the appropriate annotation and remind the designer about the features which he installed too long ago to remember, or which were installed by other designers who work with him. We will develop the fundamental principles behind such a designer's assistant and we will construct a prototype system which meets many of these desiderata.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {284-303},
 keywords     = {computer-aided design, dependencies, integrated circuits, engineering problem solving, VLSI, layout, constraints},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069456,
 author       = {Wolff, J. Gerard},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Data Compression, Generalisation and Overgeneralisation in an Evolving Theory of Language Development},
 year         = {1980},
 abstract     = {This paper describes a computer model of first language acquisition, program SNPR14, which is a development of an earlier model, MK10/GRAM15, described elsewhere [Wolff, 1978a and b]. Like the earlier model, SNPR14 shows some success in discovering a phrase-structure grammar from an unsegmented, semantics-free, language-like text given only that text as data. SNPR14 is designed to remedy certain weaknesses in MK10/GRAM15. In particular it provides a tentative answer to the problem of how it is that children, in forming syntactic generalisations, can distinguish "correct" generalisations from overgeneralisations and can eliminate the latter whilst retaining the former.The notion that language development and data compression are intimately related has been extended here: it is suggested that language development is, in part, a process of building a grammar in such a way that the effectiveness of the grammar as a means of compressing cognitive data is maximised for any given size of grammar.},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {304-313},
 series       = {AISB'80}
}

@inproceedings{10.5555/3069422.3069457,
 author       = {Wrightson, Graham},
 crossref     = {80:_proceed_aisb_confer_artif_intel_},
 title        = {Avoiding Equivalence Explosions in Theorem Proving - Propositional Logic},
 year         = {1980},
 booktitle    = {Proceedings of the 1980 AISB Conference on Artificial Intelligence},
 pages        = {314-320},
 series       = {AISB'80}
}
